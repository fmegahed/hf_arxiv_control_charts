id,submitted,updated,title,abstract,authors,affiliations,link_abstract,link_pdf,link_doi,comment,journal_ref,doi,primary_category,categories,pdf_url
2601.12221v1,2026-01-18T01:56:04Z,2026-01-18 01:56:04,A warping function-based control chart for detecting distributional changes in damage-sensitive features for structural condition assessment,"Data-driven damage detection methods achieve damage identification by analyzing changes in damage-sensitive features (DSFs) derived from structural health monitoring (SHM) data. The core reason for their effectiveness lies in the fact that damage or structural state transition can be manifested as changes in the distribution of DSF data. This enables us to reframe the problem of damage detection as one of identifying these distributional changes. Hence, developing automated tools for detecting such changes is pivotal for automated structural health diagnosis. Control charts are extensively utilized in SHM for DSF change detection, owing to their excellent online detection and early warning capabilities. However, conventional methods are primarily designed to detect mean or variance shifts, making it challenging to identify complex shape changes in distributions. This limitation results in insufficient damage detection sensitivity. Moreover, they typically exhibit poor robustness against data contamination. This paper proposes a novel control chart to address these limitations. It employs the probability density functions (PDFs) of subgrouped DSF data as monitoring objects, with shape deformations characterized by warping functions. Furthermore, a nonparametric control chart is specifically constructed for warping function monitoring in the functional data analysis framework. Key advantages of the new method include the ability to detect both shifts and complex shape deformations in distributions, excellent online detection performance, and robustness against data contamination. Extensive simulation studies demonstrate its superiority over competing approaches. Finally, the method is applied to detecting distributional changes in DSF data for cable condition assessment in a long-span cable-stayed bridge, demonstrating its practical utility in engineering.",Zhicheng Chen|Wenyu Chen|Xinyi Lei,,https://arxiv.org/abs/2601.12221v1,https://arxiv.org/pdf/2601.12221v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2601.12221v1.pdf
2601.09968v1,2026-01-15T01:08:12Z,2026-01-15 01:08:12,Derivations for the Cumulative Standardized Binomial EWMA (CSB-EWMA) Control Chart,"This paper presents the exact mathematical derivation of the mean and variance properties for the Exponentially Weighted Moving Average (EWMA) statistic applied to binomial proportion monitoring in Multiple Stream Processes (MSPs). We develop a Cumulative Standardized Binomial EWMA (CSB-EWMA) formulation that provides adaptive control limits based on exact time-varying variance calculations, overcoming the limitations of asymptotic approximations during early-phase monitoring. The derivations are rigorously validated through Monte Carlo simulations, demonstrating remarkable agreement between theoretical predictions and empirical results. This work establishes a theoretical foundation for distribution-free monitoring of binary outcomes across parallel data streams, with applications in statistical process control across diverse domains including manufacturing, healthcare, and cybersecurity.",Faruk Muritala|Austin Brown|Dhrubajyoti Ghosh|Sherry Ni,,https://arxiv.org/abs/2601.09968v1,https://arxiv.org/pdf/2601.09968v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2601.09968v1.pdf
2512.23602v1,2025-12-29T16:56:48Z,2025-12-29 16:56:48,Distribution-Free Process Monitoring with Conformal Prediction,"Traditional Statistical Process Control (SPC) is essential for quality management but is limited by its reliance on often violated statistical assumptions, leading to unreliable monitoring in modern, complex manufacturing environments. This paper introduces a hybrid framework that enhances SPC by integrating the distribution free, model agnostic guarantees of Conformal Prediction. We propose two novel applications: Conformal-Enhanced Control Charts, which visualize process uncertainty and enable proactive signals like 'uncertainty spikes', and Conformal-Enhanced Process Monitoring, which reframes multivariate control as a formal anomaly detection problem using an intuitive p-value chart. Our framework provides a more robust and statistically rigorous approach to quality control while maintaining the interpretability and ease of use of classic methods.",Christopher Burger,,https://arxiv.org/abs/2512.23602v1,https://arxiv.org/pdf/2512.23602v1,,"9 pages, 4 figures",,,cs.LG,cs.LG,https://arxiv.org/pdf/2512.23602v1.pdf
2512.01017v3,2025-11-30T18:28:09Z,2026-01-30 09:29:52,ChartAnchor: Chart Grounding with Structural-Semantic Fidelity,"Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension. Chart grounding refers to the bidirectional alignment between a chart's visual appearance and its structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important real-world applications. Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation and controlled chart-to-table reconstruction, enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.",Xinhang Li|Jingbo Zhou|Pengfei Luo|Yixiong Xiao|Tong Xu,,https://arxiv.org/abs/2512.01017v3,https://arxiv.org/pdf/2512.01017v3,,,,,cs.AI,cs.AI,https://arxiv.org/pdf/2512.01017v3.pdf
2511.13672v1,2025-11-17T18:24:29Z,2025-11-17 18:24:29,Phase I Distribution-Free Control Charts for Individual Observations Using Runs and Patterns,"Phase I distribution-free runs- and patterns-type control charts are proposed for monitoring the unknown target value (or location parameter) for both continuous and discrete individual observations. Our approach maintains the nominal in-control signal probability at a prescribed level by employing the finite Markov chain imbedding technique combined with random permutation and conditioning arguments. To elucidate the methodology, we examine two popular runs- and patterns-type statistics: the number of success runs and the scan statistic. Numerical results indicate that the performance of our proposed control charts is comparable to that of existing Phase I nonparametric control charts for individual observations.",Tung-Lung Wu,,https://arxiv.org/abs/2511.13672v1,https://arxiv.org/pdf/2511.13672v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2511.13672v1.pdf
2510.11740v1,2025-10-10T20:38:35Z,2025-10-10 20:38:35,Monitoring 3D Lattice Structures in Additive Manufacturing Using Topological Data Analysis,"We present a new method for the statistical process control of lattice structures using tools from Topological Data Analysis. Motivated by applications in additive manufacturing, such as aerospace components and biomedical implants, where hollow lattice geometries are critical, the proposed framework is based on monitoring the persistent homology properties of parts. Specifically, we focus on homological features of dimensions zero and one, corresponding to connected components and one-dimensional loops, to characterize and detect changes in the topology of lattice structures. A nonparametric hypothesis testing procedure and a control charting scheme are introduced to monitor these features during production. Furthermore, we conduct extensive run-length analysis via various simulated but real-life lattice-structured parts. Our results demonstrate that persistent homology is well-suited for detecting topological anomalies in complex geometries and offers a robust, intrinsically geometrical alternative to other SPC methods for mesh and point data.",Yulin An|Xueqi Zhao|Enrique del Castillo,,https://arxiv.org/abs/2510.11740v1,https://arxiv.org/pdf/2510.11740v1,,"22 pages, 13 figures, 12 tables",,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2510.11740v1.pdf
2510.05086v1,2025-10-06T17:54:53Z,2025-10-06 17:54:53,On Improvement of Control Chart using Repetitive Sampling for Monitoring Process Mean,"In the practical industry, the most commonly used application of statistical analysis for monitoring the process mean is the control chart. Control charts are generated based on the presumption that we have a sample from a stable process. The control chart then provides a graphical display to test this presumption. In the existing estimator \textcolor{red}{$Mr$}, researchers use a technique involving repetitive sampling along with an auxiliary variable for detecting and monitoring the statistical process mean. The existing control chart, namely \textcolor{red}{$Mr$}, is based on the regression estimator of the mean using a single auxiliary variable $X$. We propose the \textcolor{red}{$Mrep$} chart using a ratio-product exponential type estimator, and the \textcolor{red}{$Mrwp$} chart with a more efficient difference-cum-exponential type estimator used in quality control for improving the process mean in terms of $ARL$. Then we compare the proposed charts \textcolor{red}{$Mrep$} and \textcolor{red}{$Mrwp$} with the existing \textcolor{red}{$Mr$} chart in terms of $ARL$. Using $ARL$ as a performance measure, better results of the proposed charts are observed for detecting shifts in the mean level of the characteristic of interest. Moreover, Monte Carlo simulation in terms of repetitive sampling is used for quality control charting and statistical process control for the betterment of the process mean.",Fahad Rafique|Saadia Masood|Shabbir Ahmad|Sadaf Amin,,https://arxiv.org/abs/2510.05086v1,https://arxiv.org/pdf/2510.05086v1,,"17 pages, 32 fiures",,,math.OC,math.OC,https://arxiv.org/pdf/2510.05086v1.pdf
2509.19820v1,2025-09-24T07:02:39Z,2025-09-24 07:02:39,High-Dimensional Statistical Process Control via Manifold Fitting and Learning,"We address the Statistical Process Control (SPC) of high-dimensional, dynamic industrial processes from two complementary perspectives: manifold fitting and manifold learning, both of which assume data lies on an underlying nonlinear, lower dimensional space. We propose two distinct monitoring frameworks for online or 'phase II' Statistical Process Control (SPC). The first method leverages state-of-the-art techniques in manifold fitting to accurately approximate the manifold where the data resides within the ambient high-dimensional space. It then monitors deviations from this manifold using a novel scalar distribution-free control chart. In contrast, the second method adopts a more traditional approach, akin to those used in linear dimensionality reduction SPC techniques, by first embedding the data into a lower-dimensional space before monitoring the embedded observations. We prove how both methods provide a controllable Type I error probability, after which they are contrasted for their corresponding fault detection ability. Extensive numerical experiments on a synthetic process and on a replicated Tennessee Eastman Process show that the conceptually simpler manifold-fitting approach achieves performance competitive with, and sometimes superior to, the more classical lower-dimensional manifold monitoring methods. In addition, we demonstrate the practical applicability of the proposed manifold-fitting approach by successfully detecting surface anomalies in a real image dataset of electrical commutators.",Burak I. Tas|Enrique del Castillo,,https://arxiv.org/abs/2509.19820v1,https://arxiv.org/pdf/2509.19820v1,,,,,stat.ML,stat.ML|cs.LG|stat.AP,https://arxiv.org/pdf/2509.19820v1.pdf
2509.19652v1,2025-09-24T00:13:58Z,2025-09-24 00:13:58,Quality-Ensured In-Situ Process Monitoring with Deep Canonical Correlation Analysis,"This paper proposes a deep learning-based approach for in-situ process monitoring that captures nonlinear relationships between in-control high-dimensional process signature signals and offline product quality data. Specifically, we introduce a Deep Canonical Correlation Analysis (DCCA)-based framework that enables the joint feature extraction and correlation analysis of multi-modal data sources, such as optical emission spectra and CT scan images, which are collected in advanced manufacturing processes. This unified framework facilitates online quality monitoring by learning quality-oriented representations without requiring labeled defective samples and avoids the non-normality issues that often degrade traditional control chart-based monitoring techniques. We provide theoretical guarantees for the method's stability and convergence and validate its effectiveness and practical applicability through simulation experiments and a real-world case study on Direct Metal Deposition (DMD) additive manufacturing.",Xiaoyang Song|Wenbo Sun|Metin Kayitmazbatir| Jionghua| Jin,Judy|Judy|Judy|Judy|,https://arxiv.org/abs/2509.19652v1,https://arxiv.org/pdf/2509.19652v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2509.19652v1.pdf
2509.03304v1,2025-09-03T13:30:27Z,2025-09-03 13:30:27,Exponentially weighted moving average chart using zero-inflated negative binomial distribution,"Zero-inflated models are frequently used to deal with data having many zeros. A commonly used model for over-dispersed data containing zeros is known as the zero-inflated Poisson model. However, to account for the heterogeneity of counts that leads to excess variance besides inflation of zeros in the data using a more flexible model than the zero-inflated Poisson model, a zero-inflated negative binomial (ZINB) is suggested. In the present study, Shewhart and exponentially weighted moving average (EWMA) control charts are suggested to monitor the ZINB data. The charts are compared using the average run length and standard deviation of run length by using extensive Monte Carlo simulations. Besides a comprehensive simulation study assuming different settings of parameters of ZINB, a real data set is used to show the practicality of the proposed charts. The results indicate that the EWMA chart is better than the Shewhart chart.",Ali Abbas|Sajid Ali|Ismail Shah,,https://arxiv.org/abs/2509.03304v1,https://arxiv.org/pdf/2509.03304v1,https://doi.org/10.1080/00949655.2024.2385014,Journal of Statistical Computation and Simulation (2024),,10.1080/00949655.2024.2385014,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2509.03304v1.pdf
2509.01243v1,2025-09-01T08:32:44Z,2025-09-01 08:32:44,A novel methodological framework for analyzing the momentum effect in tennis singles,"This paper proposes a novel methodological framework for analyzing momentum effects in tennis singles. To statistically substantiate the existence of momentum, we employ Chi-squared independence tests for the contingency table. Assuming momentum is present, we develop a momentum metric based on the entropy weight method. Subsequently, we apply a CUSUM control chart to detect change points within the derived momentum series and define a relative distance measure to quantify the intensity of momentum shifts. Furthermore, we construct a predictive model utilizing a Back Propagation neural network (BP) optimized by a Particle Swarm Optimization (PSO) algorithm. The importance of predictive features is analyzed via SHAP values. An empirical analysis applying this framework to data from the 2023 Wimbledon Men's Singles yields the following key findings: (1) Statistical evidence signifficantly supports the existence of momentum in tennis singles. (2) Incorporating momentum characteristics substantially enhances point outcome prediction performance. (3) The BP+PSO model demonstrates competitive advantages over alternative machine learning algorithms, including Random Forest, Support Vector Machines, and logistic regression. (4) SHAP value analysis identifies an athlete's unforced errors, winning shots, the momentum metric, and the momentum shift intensity as the four most critical features for predicting point outcomes.",Chang Du|Caiya Zhang|Likai Zhou,,https://arxiv.org/abs/2509.01243v1,https://arxiv.org/pdf/2509.01243v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2509.01243v1.pdf
2508.05790v1,2025-08-07T19:04:00Z,2025-08-07 19:04:00,Estimated Phase II Weibull control chart for monitoring times between events,"In statistical process control Weibull distribution can be used to model the time between events or failures (TBE) in a process with increasing decreasing or constant failure rates. Specifically it helps in monitoring processes where the time between defect occurrences is of interest providing insight into the process reliability and performance. In this paper we consider the two sided problem of monitoring either an increase or a decrease in the scale parameter of the Weibull distribution with control charts assuming the shape parameter to be fixed. A larger scale parameter indicates that events are more spread out over time suggesting fewer defects while a smaller value may suggest deterioration in the process resulting in a higher number of defects. When the scale parameter is unknown it is estimated from Phase I observations and the plug in control limits are obtained by replacing the parameter by its estimated value from the Phase I observations. Given the well accepted fact that estimated control limits often do not perform as expected, the control limits of the Weibull chart are adjusted to achieve the desired in control (IC) performance using two criteria that are conditional average run length and standard deviation of conditional ARL. A performance study is carried out in order to assess in control and out of control performances of the proposed charts.",Tanuja Negi,,https://arxiv.org/abs/2508.05790v1,https://arxiv.org/pdf/2508.05790v1,,"9 pages, 1 table",,,stat.AP,stat.AP,https://arxiv.org/pdf/2508.05790v1.pdf
2507.23732v1,2025-07-31T17:11:24Z,2025-07-31 17:11:24,Control Charts for Percentiles of Truncated Beta Distributed Environmental Data Using Studentized Bootstrap Method,"This paper proposes a control chart for monitoring percentiles of a process that follows a truncated beta distribution, utilizing a studentized parametric bootstrap method to account for the case when in-control parameters are unknown. To evaluate the in-control performance, extensive Monte Carlo simulations are conducted across various combinations of percentiles, false alarm rates, and sample sizes, with performance measured in terms of the average run length. The out-of-control performance is thoroughly assessed by introducing shifts in the distributional parameters and comparing the proposed chart with the conventional beta-based chart. The effectiveness and practical applicability of the proposed chart is illustrated through real-world examples from environmental data.",Bidhan Modok|Amarjit Kundu|Shovan Chowdhury,,https://arxiv.org/abs/2507.23732v1,https://arxiv.org/pdf/2507.23732v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2507.23732v1.pdf
2507.16749v2,2025-07-22T16:36:51Z,2026-01-10 04:59:24,Bootstrapped Control Limits for Score-Based Concept Drift Control Charts,"Monitoring for changes in a predictive relationship represented by a fitted supervised learning model (i.e., concept drift detection) is a widespread problem in modern data-driven applications. A general and powerful Fisher score-based concept drift approach was recently proposed, in which detecting concept drift reduces to detecting changes in the mean of the model's score vector using a multivariate exponentially weighted moving average (MEWMA). To implement the approach, the initial data must be split into two subsets. The first subset serves as the training sample to which the model is fit, and the second subset serves as an out-of-sample test set from which the MEWMA control limit (CL) is determined. In this paper, we retain the same score-based MEWMA monitoring statistic as the existing method and focus instead on improving the computation of the control limit. We develop a novel nested bootstrap procedure for calibrating the CL that allows the entire initial sample to be used for model fitting, thereby yielding a more accurate baseline model while eliminating the need for a large holdout set. We show that a standard nested bootstrap substantially underestimates the variability of the monitoring statistic and develop a 0.632-like correction that appropriately accounts for this. We demonstrate the advantages with numerical examples.",Jiezhong Wu|Daniel W. Apley,,https://arxiv.org/abs/2507.16749v2,https://arxiv.org/pdf/2507.16749v2,,"53 pages, 5 figures",,,stat.ME,stat.ME|stat.ML,https://arxiv.org/pdf/2507.16749v2.pdf
2507.14641v1,2025-07-19T14:35:51Z,2025-07-19 14:35:51,Deep Learning-Based Survival Analysis with Copula-Based Activation Functions for Multivariate Response Prediction,"This research integrates deep learning, copula functions, and survival analysis to effectively handle highly correlated and right-censored multivariate survival data. It introduces copula-based activation functions (Clayton, Gumbel, and their combinations) to model the nonlinear dependencies inherent in such data. Through simulation studies and analysis of real breast cancer data, our proposed CNN-LSTM with copula-based activation functions for multivariate multi-types of survival responses enhances prediction accuracy by explicitly addressing right-censored data and capturing complex patterns. The model's performance is evaluated using Shewhart control charts, focusing on the average run length (ARL).",Jong-Min Kim|Il Do Ha|Sangjin Kim,,https://arxiv.org/abs/2507.14641v1,https://arxiv.org/pdf/2507.14641v1,,,,,stat.ML,stat.ML|cs.LG,https://arxiv.org/pdf/2507.14641v1.pdf
2507.13022v1,2025-07-17T11:50:29Z,2025-07-17 11:50:29,Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers,"In the context of the health monitoring for the next generation of reusable space launchers, we outline a first step toward developing an onboard fault detection and diagnostic capability for the electrical system that controls the engine valves. Unlike existing approaches in the literature, our solution is designed to meet a broader range of key requirements. This includes estimating confidence levels for predictions, detecting out-of-distribution (OOD) cases, and controlling false alarms. The proposed solution is based on a temporal convolutional autoencoder to automatically extract low-dimensional features from raw sensor data. Fault detection and diagnosis are respectively carried out using a binary and a multiclass classifier trained on the autoencoder latent and residual spaces. The classifiers are histogram-based gradient boosting models calibrated to output probabilities that can be interpreted as confidence levels. A relatively simple technique, based on inductive conformal anomaly detection, is used to identify OOD data. We leverage other simple yet effective techniques, such as cumulative sum control chart (CUSUM) to limit the false alarms, and threshold moving to address class imbalance in fault detection. The proposed framework is highly configurable and has been evaluated on simulated data, covering both nominal and anomalous operational scenarios. The results indicate that our solution is a promising first step, though testing with real data will be necessary to ensure that it achieves the required maturity level for operational use.",Luis Basora|Louison Bocquet-Nouaille|Elinirina Robinson|Serge Le Gonidec,,https://arxiv.org/abs/2507.13022v1,https://arxiv.org/pdf/2507.13022v1,,"53 pages, 16 figures",,,cs.LG,cs.LG,https://arxiv.org/pdf/2507.13022v1.pdf
2507.12187v1,2025-07-16T12:34:17Z,2025-07-16 12:34:17,"Learning, fast and slow: a two-fold algorithm for data-based model adaptation","This article addresses the challenge of adapting data-based models over time. We propose a novel two-fold modelling architecture designed to correct plant-model mismatch caused by two types of uncertainty. Out-of-domain uncertainty arises when the system operates under conditions not represented in the initial training dataset, while in-domain uncertainty results from real-world variability and flaws in the model structure or training process. To handle out-of-domain uncertainty, a slow learning component, inspired by the human brain's slow thinking process, learns system dynamics under unexplored operating conditions, and it is activated only when a monitoring strategy deems it necessary. This component consists of an ensemble of models, featuring (i) a combination rule that weights individual models based on the statistical proximity between their training data and the current operating condition, and (ii) a monitoring algorithm based on statistical control charts that supervises the ensemble's reliability and triggers the offline training and integration of a new model when a new operating condition is detected. To address in-domain uncertainty, a fast learning component, inspired by the human brain's fast thinking process, continuously compensates in real time for the mismatch of the slow learning model. This component is implemented as a Gaussian process (GP) model, trained online at each iteration using recent data while discarding older samples. The proposed methodology is tested on a benchmark energy system referenced in the literature, demonstrating that the combined use of slow and fast learning components improves model accuracy compared to standard adaptation approaches.",Laura Boca de Giuli|Alessio La Bella|Riccardo Scattolini,,https://arxiv.org/abs/2507.12187v1,https://arxiv.org/pdf/2507.12187v1,,,,,eess.SY,eess.SY,https://arxiv.org/pdf/2507.12187v1.pdf
2506.21970v1,2025-06-27T07:21:01Z,2025-06-27 07:21:01,Non-Parametric Time Between Events and Amplitude Methods for Monitoring Drought Characteristics,"Drought is a significant natural phenomenon with profound environmental, economic, and societal impacts. Effective monitoring of drought characteristics -- such as intensity, magnitude, and duration -- is crucial for resilience and mitigation strategies. This study proposes the use of non-parametric Time Between Events and Amplitude (TBEA) control charts for detecting changes in drought characteristics, specifically applying them to the Standardized Precipitation and Evapotranspiration Index. Aware of being non-exhaustive, we considered two non-parametric change-point control charts based on the Mann-Whitney and Kolmogorov-Smirnov statistics, respectively. We studied the in-control statistical performances of the change-point control charts in the time between events and amplitude framework through a simulation study. Furthermore, we assessed the coherence of the results obtained with a distribution-free upper sided Exponentially Weighted Moving Average control chart specifically designed for monitoring TBEA data. The findings suggest that the proposed methods may serve as valuable tools for climate resilience planning and water resource management.",Michele Scagliarini,,https://arxiv.org/abs/2506.21970v1,https://arxiv.org/pdf/2506.21970v1,,"24 pages, 14 Figures",,,stat.AP,stat.AP,https://arxiv.org/pdf/2506.21970v1.pdf
2504.09684v1,2025-04-13T18:35:49Z,2025-04-13 18:35:49,An Adaptive Multivariate Functional Control Chart,"New data acquisition technologies allow one to gather huge amounts of data that are best represented as functional data. In this setting, profile monitoring assesses the stability over time of both univariate and multivariate functional quality characteristics. The detection power of profile monitoring methods could heavily depend on parameter selection criteria, which usually do not take into account any information from the out-of-control (OC) state. This work proposes a new framework, referred to as adaptive multivariate functional control chart (AMFCC), capable of adapting the monitoring of a multivariate functional quality characteristic to the unknown OC distribution, by combining $p$-values of the partial tests corresponding to Hotelling $T^2$-type statistics calculated at different parameter combinations. Through an extensive Monte Carlo simulation study, the performance of AMFCC is compared with methods that have already appeared in the literature. Finally, a case study is presented in which the proposed framework is used to monitor a resistance spot welding process in the automotive industry. AMFCC is implemented in the R package funcharts, available on CRAN.",Fabio Centofanti|Antonio Lepore|Biagio Palumbo,,https://arxiv.org/abs/2504.09684v1,https://arxiv.org/pdf/2504.09684v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2504.09684v1.pdf
2503.20131v1,2025-03-26T00:52:06Z,2025-03-26 00:52:06,Signed Rank Chart For Tied Observations: An Application of Deep Learning Models,"Shewhart Control Charts (SCC)s are constructed under the assumption of normality and are widely recognized in statistical quality control by numerous researchers. Problems arise when the distribution of process data does not conform to a typical Normal Distribution (ND) or when there is insufficient evidence to confirm that the data has approximately ND. Additionally, in some processes, Tied Observations (TO)s are present. The resolution of the measurement device used to assess a quality characteristic can lead to rounding errors, as well as TOs. In many cases, SCCs prove inadequate. In this paper, we address the challenges of non-normal observations and rounding errors by developing a Shewhart Signed-Rank Control Chart (SS-RCC) based on the Wilcoxon statistic. We define a random variable for TOs and another for Untied Observations (UO)s. Subsequently, we approximate their distributions using a Scaled-Normal Distribution (SND) and apply a Deep Learning (DL) model to estimate the scale parameters of the SND for the Control Chart (CC). In practice, we calculate the Average Run Length ($ARL$) for specific cases using Johnson-type distribution benchmarks to illustrate the effects of ties and shifts in manufacturing processes.",Seyedeh Azadeh Fallah Mortezanejad|Ruochen Wang,"School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, Jiangsu, China|School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, Jiangsu, China",https://arxiv.org/abs/2503.20131v1,https://arxiv.org/pdf/2503.20131v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2503.20131v1.pdf
2502.02296v1,2025-02-04T13:06:48Z,2025-02-04 13:06:48,On The Performance of a Two-Sided Shewhart Chart for Continuous Proportions with Estimated Parameters,"During the recent years there was an increased interest in studying the performance of different types of control charts, under various distributional models for continuous proportions, such as percentages and rates. In this work we consider the Kumaraswamy distribution, a popular and flexible distributional model for data in the unit interval (0,1) and investigate further the properties of a two-sided chart for individual observations for monitoring these types of processes, when the process parameters are unknown. Specifically, using Monte Carlo simulation, we evaluate the performance of the chart under a conditional perspective and provide empirical rules on how to select the appropriate size for the Phase I sample. In addition, we explore possible adjustments on the control limits of the chart, which take into account the available Phase I sample. The performance of the chart is also investigated for several out-of-control situations. The results show that for small and moderate size Phase I samples, practitioners have to choose whether they prefer a guaranteed in-control performance or an improved out-of-control performance. The implementation of the considered methods in practice is discussed via two numerical examples.",Athanasios C. Rakitzis,,https://arxiv.org/abs/2502.02296v1,https://arxiv.org/pdf/2502.02296v1,,"33 pages, 13 figures",,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2502.02296v1.pdf
2501.11809v1,2025-01-21T01:11:41Z,2025-01-21 01:11:41,Dynamic Risk-Adjusted Monitoring of Time Between Events: Applications of NHPP in Pipeline Accident Surveillance,"Monitoring time between events (TBE) is a critical task in industrial settings. Traditional Statistical Process Monitoring (SPM) methods often assume that TBE variables follow an exponential distribution, which implies a constant failure intensity. While this assumption may hold for products with homogeneous quality, it is less appropriate for complex systems, such as repairable systems, where failure mechanisms evolve over time due to degradation or aging. In such cases, the Non-Homogeneous Poisson Process (NHPP), which accommodates time-varying failure intensity, is a more suitable model. Furthermore, failure patterns in complex systems are frequently influenced by risk factors, including environmental conditions and human interventions, and system failures often incur restoration costs. This work introduces a novel approach: a risk-adjusted control chart based on the NHPP model, specifically designed to monitor the ratio of cost to TBE, referred to as the average cost per time unit (AC). The proposed method is evaluated through extensive simulations, demonstrating its superior performance. Additionally, the chart is applied to monitor pipeline accidents over time, accounting for the impact of various risk factors. These results highlight the effectiveness of the developed chart in enhancing monitoring capabilities for complex systems.",Hussam Ahmad|Adel Ahmadi Nadi|Mohammad Amini|Subhabrata Chakraborti,,https://arxiv.org/abs/2501.11809v1,https://arxiv.org/pdf/2501.11809v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2501.11809v1.pdf
2501.11649v1,2025-01-20T18:27:36Z,2025-01-20 18:27:36,Investigating the performance of the Phase II Hotelling T2 chart when monitoring multivariate time series observations,"Thanks to high-tech measurement systems like sensors, data are often collected with high frequency in modern industrial processes. This phenomenon could potentially produce autocorrelated and cross-correlated measurements. It has been shown that if this issue is not properly accounted for while designing the control charts, many false alarms may be observed, disrupting the monitoring process efficiency. There are generally two recommended ways to monitor autocorrelated data: fitting a time series model and then monitoring the residuals or directly monitoring the original observations. Although residual charts are popular in the literature because they offer advantages such as ease of implementation, questions have been raised about their efficiency due to the loss of information. This paper develops the methodology for applying Hotelling's T2 chart directly to monitoring multivariate autocorrelated and cross-correlated observations. To model such data, we use the multivariate vector autoregressive time series model of order p >= 1, denoted as VAR(p). We compare the performance of the T2 chart based on the original observations and the residual-based T2 chart using the well-known metric average run length and a newly introduced criterion called first-to-signal. The results indicate that the proposed method consistently outperforms the alternative chart. We also illustrate the proposed method using two examples: one from a steel sheet rolling process (VAR(1) observations) and another from a chemical process (VAR(3) observations).",Adel Ahmadi Nadi|Giovanni Celano|Stefan Steiner,,https://arxiv.org/abs/2501.11649v1,https://arxiv.org/pdf/2501.11649v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2501.11649v1.pdf
2411.14706v1,2024-11-22T03:31:28Z,2024-11-22 03:31:28,The CUSUM Test with Observation-Adjusted Control Limits in Parameters Change Detection for the Extremely Heavy-Tailed Distributions Sequences,"In this paper, we propose an new the CUSUM sequential test (control chart, stopping time) with the observation-adjusted control limits (CUSUM-OAL) for monitoring quickly and adaptively the change in distribution of a sequential observations. We give the estimation of the in-control and the out-of-control average run lengths (ARLs) of the CUSUM-OAL test. The theoretical results are illustrated by numerical simulations in detecting $α$ shifts of the extreme heavy-tailed distribution observations sequence.",F. Tang|D. Han,,https://arxiv.org/abs/2411.14706v1,https://arxiv.org/pdf/2411.14706v1,,submitted to Statistical Papers. arXiv admin note: substantial text overlap with arXiv:2303.04628,,,stat.AP,stat.AP,https://arxiv.org/pdf/2411.14706v1.pdf
2410.20138v1,2024-10-26T10:26:28Z,2024-10-26 10:26:28,Functional Mixture Regression Control Chart,"Industrial applications often exhibit multiple in-control patterns due to varying operating conditions, which makes a single functional linear model (FLM) inadequate to capture the complexity of the true relationship between a functional quality characteristic and covariates, which gives rise to the multimode profile monitoring problem. This issue is clearly illustrated in the resistance spot welding (RSW) process in the automotive industry, where different operating conditions lead to multiple in-control states. In these states, factors such as electrode tip wear and dressing may influence the functional quality characteristic differently, resulting in distinct FLMs across subpopulations. To address this problem, this article introduces the functional mixture regression control chart (FMRCC) to monitor functional quality characteristics with multiple in-control patterns and covariate information, modeled using a mixture of FLMs. A monitoring strategy based on the likelihood ratio test is proposed to monitor any deviation from the estimated in-control heterogeneous population. An extensive Monte Carlo simulation study is performed to compare the FMRCC with competing monitoring schemes that have already appeared in the literature, and a case study in the monitoring of an RSW process in the automotive industry, which motivated this research, illustrates its practical applicability.",Christian Capezza|Fabio Centofanti|Davide Forcina|Antonio Lepore|Biagio Palumbo,,https://arxiv.org/abs/2410.20138v1,https://arxiv.org/pdf/2410.20138v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2410.20138v1.pdf
2410.12736v1,2024-10-16T16:53:16Z,2024-10-16 16:53:16,A comparative study of self-starting CUSUM control charts for location shifts,"In recent years, self-starting methods have garnered increasing attention in Statistical Process Control and Monitoring (SPC/M), as they offer real-time disorder detection without the need for a calibration phase (Phase I). This study focuses on evaluating parametric self-starting CUSUM-type control charts, specifically the Bayesian Predictive Ratio CUSUM (PRC) developed by Bourazas et al. (2023) and the frequentist alternative self-starting CUSUM proposed by Hawkins and Olwell (1998). The performance of these methods is thoroughly examined through an extensive simulation study under various scenarios involving a change in the mean of Normal data. Additionally, a prior sensitivity analysis for PRC is conducted. The work ands with concluding remarks summarizing the findings.",Konstantinos Bourazas,,https://arxiv.org/abs/2410.12736v1,https://arxiv.org/pdf/2410.12736v1,,,,,stat.OT,stat.OT,https://arxiv.org/pdf/2410.12736v1.pdf
2409.04673v3,2024-09-07T01:34:13Z,2024-09-20 17:48:35,A Multi-objective Economic Statistical Design of the CUSUM chart: NSGA II Approach,"This paper presents an approach for the economic statistical design of the Cumulative Sum (CUSUM) control chart in a multi-objective optimization framework. The proposed methodology integrates economic considerations with statistical aspects to optimize the design parameters like the sample size ($n$), sampling interval ($h$), and decision interval ($H$) of the CUSUM chart. The Non-dominated Sorting Genetic Algorithm II (NSGA II) is employed to solve the multi-objective optimization problem, aiming to minimize both the average cost per cycle ($C_E$) and the out-of-control Average Run Length ($ARL_δ$) simultaneously. The effectiveness of the proposed approach is demonstrated through a numerical example by determining the optimized CUSUM chart parameters using NSGA II. Additionally, sensitivity analysis is conducted to assess the impact of variations in input parameters. The corresponding results indicate that the proposed methodology significantly reduces the expected cost per cycle by about 43% when compared to the findings of the article by M. Lee in the year 2011. A more extensive comparison with respect to both $C_E$ and $ARL_δ$ has also been provided for justifying the methodology proposed in this article. This highlights the practical relevance and potential of this study for the right application of the technique of the CUSUM chart for process control purposes in industries.", Sandeep|Arup Ranjan Mukhopadhyay,,https://arxiv.org/abs/2409.04673v3,https://arxiv.org/pdf/2409.04673v3,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2409.04673v3.pdf
2408.17022v2,2024-08-30T05:29:21Z,2025-05-04 11:25:20,Nonparametric Monitoring of Spatial Dependence,"In process monitoring, it is common for measurements to be taken regularly or randomly from different spatial locations in two or three dimensions. While there are nonparametric methods for process monitoring with such spatial data to detect changes in the mean, there is a gap in the literature for nonparametric control charting methods developed to monitor spatial dependence. This study considers streams of regular, rectangular data sets using spatial ordinal patterns (SOPs) as a nonparametric method to detect spatial dependencies. We propose novel SOP control charts, which are distribution-free and do not require prior Phase-I analysis. To uncover higher-order dependencies, we develop a new class of statistics that combines SOPs with the Box-Pierce approach. An extensive simulation study demonstrates the superiority and effectiveness of our proposed charts over traditional parametric approaches, particularly when the spatial dependence is nonlinear or bilateral or when the spatial data contains outliers. The proposed SOP control charts are illustrated using real-world datasets to detect (i) heavy rainfall in Germany, (ii) war-related fires in (eastern) Ukraine, and (iii) manufacturing defects in textile production. This wide range of applications and findings demonstrates the broad utility of the proposed nonparametric control charts. In addition, all methods in this study are provided as a publicly available \texttt{Julia} package on \href{https://github.com/AdaemmerP/OrdinalPatterns.jl}{GitHub} for further implementations.",Philipp Adämmer|Philipp Wittenberg|Christian H. Weiß|Murat Caner Testik,,https://arxiv.org/abs/2408.17022v2,https://arxiv.org/pdf/2408.17022v2,,"38 pages, 9 figures, 19 tables",,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2408.17022v2.pdf
2407.17236v2,2024-07-24T12:45:02Z,2024-07-25 06:21:01,Statistical Batch-Based Bearing Fault Detection,"In the domain of rotating machinery, bearings are vulnerable to different mechanical faults, including ball, inner, and outer race faults. Various techniques can be used in condition-based monitoring, from classical signal analysis to deep learning methods. Based on the complex working conditions of rotary machines, multivariate statistical process control charts such as Hotelling's $T^2$ and Squared Prediction Error are useful for providing early warnings. However, these methods are rarely applied to condition monitoring of rotating machinery due to the univariate nature of the datasets. In the present paper, we propose a multivariate statistical process control-based fault detection method that utilizes multivariate data composed of Fourier transform features extracted for fixed-time batches. Our approach makes use of the multidimensional nature of Fourier transform characteristics, which record more detailed information about the machine's status, in an effort to enhance early defect detection and diagnosis. Experiments with varying vibration measurement locations (Fan End, Drive End), fault types (ball, inner, and outer race faults), and motor loads (0-3 horsepower) are used to validate the suggested approach. The outcomes illustrate our method's effectiveness in fault detection and point to possible broader uses in industrial maintenance.",Victoria Jorry|Zina-Sabrina Duma|Tuomas Sihvonen|Satu-Pia Reinikainen|Lassi Roininen,,https://arxiv.org/abs/2407.17236v2,https://arxiv.org/pdf/2407.17236v2,,,,,stat.ML,stat.ML|cs.LG,https://arxiv.org/pdf/2407.17236v2.pdf
2407.09074v1,2024-07-12T07:56:46Z,2024-07-12 07:56:46,Real-time Pipe Burst Localization in Water Distribution Networks Using Change Point Detection Algorithms,"Change point detection (CPD) has proved to be an effective tool for detecting drifts in data and its use over the years has become more pronounced due to the vast amount of data and IoT devices readily available. This study analyzes the effectiveness of Cumulative Sum (CUSUM) and Shewhart Control Charts for identifying the occurrence of abrupt pressure changes for pipe burst localization in Water Distribution Network (WDN). Change point detection algorithms could be useful for identifying the nodes that register the earliest and most drastic pressure changes with the aim of detecting pipe bursts in real-time. TSNet, a Python package, is employed in order to simulate pipe bursts in a WDN. The pressure readings are served to the pipe burst localization algorithm the moment they are available for real-time pie burst localization. The performance of the pipe burst localization algorithm is evaluated using a key metric such as localization accuracy under different settings to compare its performance when paired with either CUSUM or Shewhart. Results show that the pipe burst localization algorithm has an overall better performance when paired with CUSUM. Although, it does show great accuracy for both CPD algorithms when pressure readings are being continuously made available without a big gap between time steps. The proposed approach however still needs further experiments on different WDNs to assess the performance and accuracy of the algorithm on real-world WDN models.",Takudzwa Mzembegwa|Clement N Nyirenda,,https://arxiv.org/abs/2407.09074v1,https://arxiv.org/pdf/2407.09074v1,,8 pages,,,eess.SY,eess.SY,https://arxiv.org/pdf/2407.09074v1.pdf
2404.16496v2,2024-04-25T10:41:12Z,2025-02-26 11:14:25,Probabilistic Multi-Layer Perceptrons for Wind Farm Condition Monitoring,"We provide a condition monitoring system for wind farms, based on normal behaviour modelling using a probabilistic multi-layer perceptron with transfer learning via fine-tuning. The model predicts the output power of the wind turbine under normal behaviour based on features retrieved from supervisory control and data acquisition (SCADA) systems. Its advantages are that (i) it can be trained with SCADA data of at least a few years, (ii) it can incorporate all SCADA data of all wind turbines in a wind farm as features, (iii) it assumes that the output power follows a normal density with heteroscedastic variance and (iv) it can predict the output of one wind turbine by borrowing strength from the data of all other wind turbines in a farm. Probabilistic guidelines for condition monitoring are given via a cumulative sum (CUSUM) control chart, which is specifically designed based on a real-data classification exercise and, hence, is adapted to the needs of a wind farm. We illustrate the performance of our model in a real SCADA data example which provides evidence that it outperforms other probabilistic prediction models.",Filippo Fiocchi|Domna Ladopoulou|Petros Dellaportas,,https://arxiv.org/abs/2404.16496v2,https://arxiv.org/pdf/2404.16496v2,https://doi.org/10.1002/we.70012,"10 pages, 9 figures, 3 tables","Wind Energy, 28(4) (2025), e70012",10.1002/we.70012,cs.LG,cs.LG|stat.AP,https://arxiv.org/pdf/2404.16496v2.pdf
2404.05282v1,2024-04-08T08:16:35Z,2024-04-08 08:16:35,Prediction intervals for overdispersed Poisson data and their application in medical and pre-clinical quality control,"In pre-clinical and medical quality control, it is of interest to assess the stability of the process under monitoring or to validate a current observation using historical control data. Classically, this is done by the application of historical control limits (HCL) graphically displayed in control charts. In many applications, HCL are applied to count data, e.g. the number of revertant colonies (Ames assay) or the number of relapses per multiple sclerosis patient. Count data may be overdispersed, can be heavily right-skewed and clusters may differ in cluster size or other baseline quantities (e.g. number of petri dishes per control group or different length of monitoring times per patient).
  Based on the quasi-Poisson assumption or the negative-binomial distribution, we propose prediction intervals for overdispersed count data to be used as HCL. Variable baseline quantities are accounted for by offsets. Furthermore, we provide a bootstrap calibration algorithm that accounts for the skewed distribution and achieves equal tail probabilities.
  Comprehensive Monte-Carlo simulations assessing the coverage probabilities of eight different methods for HCL calculation reveal, that the bootstrap calibrated prediction intervals control the type-1-error best. Heuristics traditionally used in control charts (e.g. the limits in Sheward c- or u-charts or the mean plus minus 2 SD) fail to control a pre-specified coverage probability.
  The application of HCL is demonstrated based on data from the Ames assay and for numbers of relapses of multiple sclerosis patients. The proposed prediction intervals and the algorithm for bootstrap calibration are publicly available via the R package predint.",Max Menssen|Martina Dammann|Firas Fneish|David Ellenberger|Frank Schaarschmid,,https://arxiv.org/abs/2404.05282v1,https://arxiv.org/pdf/2404.05282v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2404.05282v1.pdf
2403.09138v1,2024-03-14T07:27:26Z,2024-03-14 07:27:26,"Study on Standardizing Working Time: A Case of XYZ Retail Store in Bandung, Indonesia","Work time standardization helps to find and reduce wasteful movements and time in the workplace, such as chatting, mobile phone use, insufficient rest, or unproductive tasks. This study aims to map the process of displaying products from the warehouse to the shelves and calculate and determine the standard working time of employees of the Operations Division of PT XYZ Branch who oversee displaying X Milk and Y Bread. The data was collected six times in three weeks, including interviews and observations, and took a sample of 20 pieces on each product to carry out data analysis such as data sufficiency tests and control charts. Several time deviations were found in the display process of X Milk products on all observation days in different activities. Whereas in the process of displaying Y Bread, only the deviation of working time was found on the 4th observation day, which proves that the process needs to have a standard working time so that the activity work time is more controlled. Therefore, the analysis is carried out with the calculation of performance rating, time allowance, normal time, and standard time. The result of the standard time calculation for the display process of X Milk products is 15.83 minutes and Y Bread is 9.18 minutes for each product of 20 units.",Aprodhita Anindya Putri|Akhmad Yunani,,https://arxiv.org/abs/2403.09138v1,https://arxiv.org/pdf/2403.09138v1,,"9 pages, 11 tables, and 3 figures","International Research Journal of Economics and Management Studies, Vol. 3, No. 2, pp. 86-94, 2024",,econ.GN,econ.GN,https://arxiv.org/pdf/2403.09138v1.pdf
2403.03837v2,2024-03-06T16:28:31Z,2024-10-26 11:31:55,An Adaptive Multivariate Functional EWMA Control Chart,"In many modern industrial scenarios, the measurements of the quality characteristics of interest are often required to be represented as functional data or profiles. This motivates the growing interest in extending traditional univariate statistical process monitoring (SPM) schemes to the functional data setting. This article proposes a new SPM scheme, which is referred to as adaptive multivariate functional EWMA (AMFEWMA), to extend the well-known exponentially weighted moving average (EWMA) control chart from the univariate scalar to the multivariate functional setting. The favorable performance of the AMFEWMA control chart over existing methods is assessed via an extensive Monte Carlo simulation. Its practical applicability is demonstrated through a case study in the monitoring of the quality of a resistance spot welding process in the automotive industry through the online observations of dynamic resistance curves, which are associated with multiple spot welds on the same car body and recognized as the full technological signature of the process.",Christian Capezza|Giovanna Capizzi|Fabio Centofanti|Antonio Lepore|Biagio Palumbo,,https://arxiv.org/abs/2403.03837v2,https://arxiv.org/pdf/2403.03837v2,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2403.03837v2.pdf
2401.11789v1,2024-01-22T09:40:51Z,2024-01-22 09:40:51,Stein EWMA Control Charts for Count Processes,"The monitoring of serially independent or autocorrelated count processes is considered, having a Poisson or (negative) binomial marginal distribution under in-control conditions. Utilizing the corresponding Stein identities, exponentially weighted moving-average (EWMA) control charts are constructed, which can be flexibly adapted to uncover zero inflation, over- or underdispersion. The proposed Stein EWMA charts' performance is investigated by simulations, and their usefulness is demonstrated by a real-world data example from health surveillance.",Christian H. Weiß,,https://arxiv.org/abs/2401.11789v1,https://arxiv.org/pdf/2401.11789v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2401.11789v1.pdf
2401.10605v1,2024-01-19T10:23:14Z,2024-01-19 10:23:14,The Unconditional Performance of Control Charts for Zero-Inflated Processes with Estimated Parameters,"Control charts for zero-inflated processes have attracted the interest of the researchers in the recent years. In this work we investigate the performance of Shewhart-type charts for zero-inflated Poisson and zero-inflated Binomial processes, in the case of estimated parameters. This is a case that usually occurs in practice, especially prior to starting the process monitoring. Using Monte Carlo simulation we evaluate charts' performance under an unconditional perspective and provide guidelines for their use in practice. We examine both the in-control and the out-of-control performance.",Athanasios C. Rakitzis|Eftychia Mamzeridou|Petros E. Maravelakis,,https://arxiv.org/abs/2401.10605v1,https://arxiv.org/pdf/2401.10605v1,,21 pages,,,stat.AP,stat.AP,https://arxiv.org/pdf/2401.10605v1.pdf
2312.16357v1,2023-12-26T23:50:52Z,2023-12-26 23:50:52,Statistical monitoring of European cross-border physical electricity flows using novel temporal edge network processes,"Conventional modelling of networks evolving in time focuses on capturing variations in the network structure. However, the network might be static from the origin or experience only deterministic, regulated changes in its structure, providing either a physical infrastructure or a specified connection arrangement for some other processes. Thus, to detect change in its exploitation, we need to focus on the processes happening on the network. In this work, we present the concept of monitoring random Temporal Edge Network (TEN) processes that take place on the edges of a graph having a fixed structure. Our framework is based on the Generalized Network Autoregressive statistical models with time-dependent exogenous variables (GNARX models) and Cumulative Sum (CUSUM) control charts. To demonstrate its effective detection of various types of change, we conduct a simulation study and monitor the real-world data of cross-border physical electricity flows in Europe.",Anna Malinovskaya|Rebecca Killick|Kathryn Leeming|Philipp Otto,,https://arxiv.org/abs/2312.16357v1,https://arxiv.org/pdf/2312.16357v1,,,,,stat.AP,stat.AP|stat.ME,https://arxiv.org/pdf/2312.16357v1.pdf
2311.11050v1,2023-11-18T12:15:58Z,2023-11-18 12:15:58,Functional Neural Network Control Chart,"In many Industry 4.0 data analytics applications, quality characteristic data acquired from manufacturing processes are better modeled as functions, often referred to as profiles. In practice, there are situations where a scalar quality characteristic, referred to also as the response, is influenced by one or more variables in the form of functional data, referred to as functional covariates. To adjust the monitoring of the scalar response by the effect of this additional information, a new profile monitoring strategy is proposed on the residuals obtained from the functional neural network, which is able to learn a possibly nonlinear relationship between the scalar response and the functional covariates. An extensive Monte Carlo simulation study is performed to assess the performance of the proposed method with respect to other control charts that appeared in the literature before. Finally, a case study in the railway industry is presented with the aim of monitoring the heating, ventilation and air conditioning systems installed onboard passenger trains.",Murat Kulahci|Antonio Lepore|Biagio Palumbo|Gianluca Sposito,,https://arxiv.org/abs/2311.11050v1,https://arxiv.org/pdf/2311.11050v1,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2311.11050v1.pdf
2311.02411v1,2023-11-04T14:22:19Z,2023-11-04 14:22:19,A Directional Monitoring Approach of Sequential Incomplete Wind Power Curves with Copula-based Variational Inference,"Wind turbines often work under complex conditions which result in performance degradation. Accurate performance degradation monitoring is essential to ensure the reliable operation of wind turbines and reduce the maintenance costs. Wind turbine power curve monitoring is an effective way to detect performance degradation. However, due to the intermittency and fluctuation of wind speed, the wind speed range varies at different time periods, making power curves difficult to compare. Motivated by this, we proposed copula-based variational inference framework and used it to establish a sequential incomplete wind power curve estimation algorithm. First, a monotone power curve is constructed based on copula-based variational inference and integrated spline regression model. Besides, the prior distribution of model parameters are sequentially updated. Then, a directional control chart based on a new statistic named KLdivergence factor is constructed to monitor wind turbine performance degradation. The real data of a wind farm in the east of the United Kingdom shows that the proposed method can both improve the accuracy of wind turbine power curve modeling and monitor wind turbine performance degradation more precisely and comprehensively than the existing approaches.",Peng Wang|Yanting Li|Fugee Tsung,,https://arxiv.org/abs/2311.02411v1,https://arxiv.org/pdf/2311.02411v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2311.02411v1.pdf
2310.12876v2,2023-10-19T16:30:39Z,2024-04-10 19:15:44,Statistical Process Monitoring of Isolated and Persistent Defects in Complex Geometrical Shapes,"Traditional Statistical Process Control methodologies face several challenges when monitoring defects in complex geometries, such as those of products obtained via Additive Manufacturing techniques. Many approaches cannot be applied in these settings due to the high dimensionality of the data and the lack of parametric and distributional assumptions on the object shapes. Motivated by a case study involving the monitoring of egg-shaped trabecular structures, we investigate two recently-proposed methodologies to detect deviations from the nominal IC model caused by excess or lack of material. Our study focuses on the detection of both isolated large changes in the geometric structure, as well as persistent small deviations. We compare the approach of Scimone et al. (2022) with Zhao and del Castillo (2021) for monitoring defects in a small Phase I sample of 3D-printed objects. While the former control chart is able to detect large defects, the latter allows the detection of nonconforming objects with persistent small defects. Furthermore, we address the fundamental issue of selecting the number of eigenvalues to be monitored in Zhao and del Castillo's method by proposing a dimensionality reduction technique based on kernel principal components. This approach is shown to provide a good detection capability even when considering a large number of eigenvalues. By leveraging the sensitivity of the two monitoring schemes to different magnitudes of nonconformities, we also propose a novel joint monitoring scheme that is capable of identifying both types of defects in the considered case study. Computer code in R and Matlab that implements these methods and replicates the results is available as part of the supplementary material.",Sara Bonacina|Daniele Zago|Giovanna Capizzi|Bianca Maria Colosimo,,https://arxiv.org/abs/2310.12876v2,https://arxiv.org/pdf/2310.12876v2,,"We identified some issues in applying the LB method to the data in the study, which impacted the accuracy and reliability of the results. We sincerely thank Professor Enrique del Castillo and Yulin An for their valuable comments and insights, which helped identifying these issues. We appreciate their contributions and are currently in the process of revising and improving the manuscript",,,stat.AP,stat.AP,https://arxiv.org/pdf/2310.12876v2.pdf
2309.11776v1,2023-09-21T04:36:52Z,2023-09-21 04:36:52,Control Chart for Generalized Weibull Quantiles under Hybrid Censoring,"In this article, bootstrap and Shewhart type process control monitoring schemes are proposed for the quantiles of generalized Weibull distribution under hybrid censoring. Monitoring schemes for the quantiles of Weibull, generalized exponential, Rayleigh, and Burr type $X$ distributions for type I, type II and hybrid censoring can be obtained as the special cases of the proposed schemes. The maximum likelihood estimators are derived under hybrid censoring using EM algorithm and the asymptotic properties of the estimators are discussed in order to develop the Shewhart type scheme. The in-control performance of the schemes is examined in a simulation study on the basis of the average run length for different choices of quantiles, false-alarm rates and sample sizes. Behavior of the out-of-control performance of the schemes is studied for several choices of shifts in the parameters of the chosen density function. The proposed monitoring schemes are illustrated with an example from healthcare and compared with similar schemes under type I and type II censoring. The schemes are found to detect out-of-control signals effectively in terms of frequency and speed both.",Amarjit Kundu|Shovan Chowdhury|Bidhan Modok,,https://arxiv.org/abs/2309.11776v1,https://arxiv.org/pdf/2309.11776v1,,"22 pages, 12 figures",,,stat.ME,stat.ME,https://arxiv.org/pdf/2309.11776v1.pdf
2309.01978v1,2023-09-05T06:13:09Z,2023-09-05 06:13:09,An LSTM-Based Predictive Monitoring Method for Data with Time-varying Variability,"The recurrent neural network and its variants have shown great success in processing sequences in recent years. However, this deep neural network has not aroused much attention in anomaly detection through predictively process monitoring. Furthermore, the traditional statistic models work on assumptions and hypothesis tests, while neural network (NN) models do not need that many assumptions. This flexibility enables NN models to work efficiently on data with time-varying variability, a common inherent aspect of data in practice. This paper explores the ability of the recurrent neural network structure to monitor processes and proposes a control chart based on long short-term memory (LSTM) prediction intervals for data with time-varying variability. The simulation studies provide empirical evidence that the proposed model outperforms other NN-based predictive monitoring methods for mean shift detection. The proposed method is also applied to time series sensor data, which confirms that the proposed method is an effective technique for detecting abnormalities.",Jiaqi Qiu|Yu Lin|Inez Zwetsloot,,https://arxiv.org/abs/2309.01978v1,https://arxiv.org/pdf/2309.01978v1,,"19 pages, 9 figures, 6 tables",,,cs.LG,cs.LG|stat.ME,https://arxiv.org/pdf/2309.01978v1.pdf
2308.11724v2,2023-08-22T18:30:53Z,2023-09-05 04:03:48,MolSieve: A Progressive Visual Analytics System for Molecular Dynamics Simulations,"Molecular Dynamics (MD) simulations are ubiquitous in cutting-edge physio-chemical research. They provide critical insights into how a physical system evolves over time given a model of interatomic interactions. Understanding a system's evolution is key to selecting the best candidates for new drugs, materials for manufacturing, and countless other practical applications. With today's technology, these simulations can encompass millions of unit transitions between discrete molecular structures, spanning up to several milliseconds of real time. Attempting to perform a brute-force analysis with data-sets of this size is not only computationally impractical, but would not shed light on the physically-relevant features of the data. Moreover, there is a need to analyze simulation ensembles in order to compare similar processes in differing environments. These problems call for an approach that is analytically transparent, computationally efficient, and flexible enough to handle the variety found in materials based research. In order to address these problems, we introduce MolSieve, a progressive visual analytics system that enables the comparison of multiple long-duration simulations. Using MolSieve, analysts are able to quickly identify and compare regions of interest within immense simulations through its combination of control charts, data-reduction techniques, and highly informative visual components. A simple programming interface is provided which allows experts to fit MolSieve to their needs. To demonstrate the efficacy of our approach, we present two case studies of MolSieve and report on findings from domain collaborators.",Rostyslav Hnatyshyn|Jieqiong Zhao|Danny Perez|James Ahrens|Ross Maciejewski,,https://arxiv.org/abs/2308.11724v2,https://arxiv.org/pdf/2308.11724v2,,Updated references to GPCCA,,,physics.comp-ph,physics.comp-ph|cs.GR|cs.HC,https://arxiv.org/pdf/2308.11724v2.pdf
2307.10509v1,2023-07-20T00:18:38Z,2023-07-20 00:18:38,An Iterative Wavelet Threshold for Signal Denoising,"This paper introduces an adaptive filtering process based on shrinking wavelet coefficients from the corresponding signal wavelet representation. The filtering procedure considers a threshold method determined by an iterative algorithm inspired by the control charts application, which is a tool of the statistical process control (SPC). The proposed method, called SpcShrink, is able to discriminate wavelet coefficients that significantly represent the signal of interest. The SpcShrink is algorithmically presented and numerically evaluated according to Monte Carlo simulations. Two empirical applications to real biomedical data filtering are also included and discussed. The SpcShrink shows superior performance when compared with competing algorithms.",F. M. Bayer|A. J. Kozakevicius|R. J. Cintra,,https://arxiv.org/abs/2307.10509v1,https://arxiv.org/pdf/2307.10509v1,https://doi.org/10.1016/j.sigpro.2019.04.005,"19 pages, 10 figures, 2 tables","Signal Processing, Volume 162, September 2019, Pages 10-20",10.1016/j.sigpro.2019.04.005,stat.ME,stat.ME|eess.SP|math.NA|math.ST|physics.data-an,https://arxiv.org/pdf/2307.10509v1.pdf
2305.19006v1,2023-05-30T13:03:52Z,2023-05-30 13:03:52,Control Charts for Poisson Counts based on the Stein-Chen Identity,"If monitoring Poisson count data for a possible mean shift (while the Poisson distribution is preserved), then the ordinary Poisson exponentially weighted moving-average (EWMA) control chart proved to be a good solution. In practice, however, mean shifts might occur in combination with further changes in the distribution family. Or due to a misspecification during Phase-I analysis, the Poisson assumption might not be appropriate at all. In such cases, the ordinary EWMA chart might not perform satisfactorily. Therefore, two novel classes of generalized EWMA charts are proposed, which utilize the so-called Stein-Chen identity and are thus sensitive to further distributional changes than just sole mean shifts. Their average run length (ARL) performance is investigated with simulations, where it becomes clear that especially the class of so-called ""ABC-EWMA charts"" shows an appealing ARL performance. The practical application of the novel Stein-Chen EWMA charts is illustrated with an application to count data from semiconductor manufacturing.",Christian H. Weiß,,https://arxiv.org/abs/2305.19006v1,https://arxiv.org/pdf/2305.19006v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2305.19006v1.pdf
2303.04628v1,2023-03-08T14:46:59Z,2023-03-08 14:46:59,An CUSUM Test with Observation-Adjusted Control Limits in Change Detection,"In this paper, we not only propose an new optimal sequential test of sum of logarithmic likelihood ratio (SLR) but also present the CUSUM sequential test (control chart, stopping time) with the observation-adjusted control limits (CUSUM-OAL) for monitoring quickly and adaptively the change in distribution of a sequential observations. Two limiting relationships between the optimal test and a series of the CUSUM-OAL tests are established. Moreover, we give the estimation of the in-control and the out-of-control average run lengths (ARLs) of the CUSUM-OAL test. The theoretical results are illustrated by numerical simulations in detecting mean shifts of the observations sequence.",Fuquan Tang|Dong Han,,https://arxiv.org/abs/2303.04628v1,https://arxiv.org/pdf/2303.04628v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2303.04628v1.pdf
2302.07658v2,2023-02-15T13:43:25Z,2024-06-18 12:36:40,SUrvival Control Chart EStimation Software in R: the success package,"Monitoring the quality of statistical processes has been of great importance, mostly in industrial applications. Control charts are widely used for this purpose, but often lack the possibility to monitor survival outcomes. Recently, inspecting survival outcomes has become of interest, especially in medical settings where outcomes often depend on risk factors of patients. For this reason many new survival control charts have been devised and existing ones have been extended to incorporate survival outcomes. The R package success allows users to construct risk-adjusted control charts for survival data. Functions to determine control chart parameters are included, which can be used even without expert knowledge on the subject of control charts. The package allows to create static as well as interactive charts, which are built using ggplot2 (Wickham 2016) and plotly (Sievert 2020).",Daniel Gomon|Marta Fiocco|Hein Putter|Mirko Signorelli,,https://arxiv.org/abs/2302.07658v2,https://arxiv.org/pdf/2302.07658v2,,"29 pages, 10 figures, guide for the R package success, see https://cran.r-project.org/package=success Published version of the article",,,stat.AP,stat.AP|stat.ME,https://arxiv.org/pdf/2302.07658v2.pdf
2212.10731v1,2022-12-21T02:59:05Z,2022-12-21 02:59:05,Development of robust X-bar charts with unequal sample sizes,"The traditional variable control charts, such as the X-bar chart, are widely used to monitor variation in a process. They have been shown to perform well for monitoring processes under the general assumptions that the observations are normally distributed without data contamination and that the sample sizes from the process are all equal. However, these two assumptions may not be met and satisfied in many practical applications and thus make them potentially limited for widespread application especially in production processes. In this paper, we alleviate this limitation by providing a novel method for constructing the robust X-bar control charts, which can simultaneously deal with both data contamination and unequal sample sizes. The proposed method for the process parameters is optimal in a sense of the best linear unbiased estimation. Numerical results from extensive Monte Carlo simulations and a real data analysis reveal that traditional control charts seriously underperform for monitoring process in the presence of data contamination and are extremely sensitive to even a single contaminated value, while the proposed robust control charts outperform in a manner that is comparable with the traditional ones, whereas they are far superior when the data are contaminated by outliers.",Chanseok Park|Linhan Ouyang|Min Wang,,https://arxiv.org/abs/2212.10731v1,https://arxiv.org/pdf/2212.10731v1,,"27 pages, 10 figures",,,stat.ME,stat.ME,https://arxiv.org/pdf/2212.10731v1.pdf
2210.16679v1,2022-10-29T19:58:15Z,2022-10-29 19:58:15,Monitoring the Dynamic Networks of Stock Returns,"In this paper, we study the connection between the companies in the Swedish capital market. We consider 28 companies included in the determination of the market index OMX30. The network structure of the market is constructed using different methods to determine the distance between the companies. We use hierarchical clustering methods to find the relation among the companies in each window. Next, we obtain one-dimensional time series of the distances between the clustering trees that reflect the changes in the relationship between the companies in the market over time. The method of statistical process control, namely the Shewhart control chart, is applied to those time series to detect abnormal changes in the financial market.",Elena Farahbakhsh Touli|Hoang Nguyen|Olha Bodnar,,https://arxiv.org/abs/2210.16679v1,https://arxiv.org/pdf/2210.16679v1,,,,,q-fin.ST,q-fin.ST|cs.LG|math.ST,https://arxiv.org/pdf/2210.16679v1.pdf
2210.15773v2,2022-10-27T21:11:05Z,2023-01-20 14:45:29,Data-Driven Thermal Anomaly Detection in Large Battery Packs,"The early detection and tracing of anomalous operations in battery packs are critical to improving performance and ensuring safety. This paper presents a data-driven approach for online anomaly detection in battery packs that uses real-time voltage and temperature data from multiple Li-ion battery cells. Mean-based residuals are generated for cell groups and evaluated using Principal Component Analysis. The evaluated residuals are then thresholded using a cumulative sum control chart to detect anomalies. The mild external short circuits associated with cell balancing are detected in the voltage signals and necessitate voltage retraining after balancing. Temperature residuals prove to be critical, enabling anomaly detection of module balancing events within 14 min that are unobservable from the voltage residuals. Statistical testing of the proposed approach is performed on the experimental data from a battery electric locomotive injected with model-based anomalies. The proposed anomaly detection approach has a low false-positive rate and accurately detects and traces the synthetic voltage and temperature anomalies. The performance of the proposed approach compared with direct thresholding of mean-based residuals shows a 56% faster detection time, 42% fewer false negatives, and 60% fewer missed anomalies while maintaining a comparable false-positive rate.",Kiran Bhaskar|Ajith Kumar|James Bunce|Jacob Pressman|Neil Burkell|Christopher D. Rahn,,https://arxiv.org/abs/2210.15773v2,https://arxiv.org/pdf/2210.15773v2,https://doi.org/10.3390/batteries9020070,,"Batteries 2023, Volume 9(2), Article-number 70",10.3390/batteries9020070,eess.SY,eess.SY,https://arxiv.org/pdf/2210.15773v2.pdf
2209.07436v2,2022-09-15T16:33:36Z,2023-07-27 07:47:49,Statistical process monitoring of artificial neural networks,"The rapid advancement of models based on artificial intelligence demands innovative monitoring techniques which can operate in real time with low computational costs. In machine learning, especially if we consider artificial neural networks (ANNs), the models are often trained in a supervised manner. Consequently, the learned relationship between the input and the output must remain valid during the model's deployment. If this stationarity assumption holds, we can conclude that the ANN provides accurate predictions. Otherwise, the retraining or rebuilding of the model is required. We propose considering the latent feature representation of the data (called ""embedding"") generated by the ANN to determine the time when the data stream starts being nonstationary. In particular, we monitor embeddings by applying multivariate control charts based on the data depth calculation and normalized ranks. The performance of the introduced method is compared with benchmark approaches for various ANN architectures and different underlying data formats.",Anna Malinovskaya|Pavlo Mozharovskyi|Philipp Otto,,https://arxiv.org/abs/2209.07436v2,https://arxiv.org/pdf/2209.07436v2,https://doi.org/10.1080/00401706.2023.2239886,,"Technometrics, 2023",10.1080/00401706.2023.2239886,stat.ME,stat.ME|cs.LG|stat.AP|stat.ML,https://arxiv.org/pdf/2209.07436v2.pdf
2207.12331v1,2022-07-25T16:41:32Z,2022-07-25 16:41:32,Adaptive data collection for intra-individual studies affected by adherence,"Recently the use of mobile technologies in Ecological Momentary Assessments (EMA) and Interventions (EMI) has made it easier to collect data suitable for intra-individual variability studies in the medical field. Nevertheless, especially when self-reports are used during the data collection process, there are difficulties in balancing data quality and the burden placed on the subjects. In this paper, we address this problem for a specific EMA setting which aims to submit a demanding task to subjects at high/low values of a self-reported variable. We adopt a dynamic approach inspired by control chart methods and design optimization techniques to obtain an EMA triggering mechanism for data collection which takes into account both the individual variability of the self-reported variable and of the adherence rate. We test the algorithm in both a simulation setting and with real, large-scale data from a tinnitus longitudinal study. A Wilcoxon-Mann-Whitney Rank Sum Test shows that the algorithm tends to have both a higher F1 score and utility than a random schedule and a rule-based algorithm with static thresholds, which are the current state-of-the-art approaches. In conclusion, the algorithm is proven effective in balancing data quality and the burden placed on the participants, especially, as the analysis performed suggest, in studies where data collection is impacted by adherence.",Greta Monacelli|Lili Zhang|Winfried Schlee|Berthold Langguth|Tomás E. Ward|Thomas B. Murphy,,https://arxiv.org/abs/2207.12331v1,https://arxiv.org/pdf/2207.12331v1,https://doi.org/10.1002/bimj.202200203,"12 pages, 4 figures",,10.1002/bimj.202200203,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2207.12331v1.pdf
2207.09321v2,2022-07-19T15:19:33Z,2024-10-26 11:42:08,funcharts: Control charts for multivariate functional data in R,"Modern statistical process monitoring (SPM) applications focus on profile monitoring, i.e., the monitoring of process quality characteristics that can be modeled as profiles, also known as functional data. Despite the large interest in the profile monitoring literature, there is still a lack of software to facilitate its practical application. This article introduces the funcharts R package that implements recent developments on the SPM of multivariate functional quality characteristics, possibly adjusted by the influence of additional variables, referred to as covariates. The package also implements the real-time version of all control charting procedures to monitor profiles partially observed up to an intermediate domain point. The package is illustrated both through its built-in data generator and a real-case study on the SPM of Ro-Pax ship CO2 emissions during navigation, which is based on the ShipNavigation data provided in the Supplementary Material.",Christian Capezza|Fabio Centofanti|Antonio Lepore|Alessandra Menafoglio|Biagio Palumbo|Simone Vantini,,https://arxiv.org/abs/2207.09321v2,https://arxiv.org/pdf/2207.09321v2,,,,,stat.CO,stat.CO,https://arxiv.org/pdf/2207.09321v2.pdf
2207.07978v3,2022-07-16T16:42:44Z,2024-04-16 11:04:34,Robust Multivariate Functional Control Chart,"In modern Industry 4.0 applications, a huge amount of data is acquired during manufacturing processes that are often contaminated with anomalous observations in the form of both casewise and cellwise outliers. These can seriously reduce the performance of control charting procedures, especially in complex and high-dimensional settings. To mitigate this issue in the context of profile monitoring, we propose a new framework, referred to as robust multivariate functional control chart (RoMFCC), that is able to monitor multivariate functional data while being robust to both functional casewise and cellwise outliers. The RoMFCC relies on four main elements: (I) a functional univariate filter to identify functional cellwise outliers to be replaced by missing components; (II) a robust multivariate functional data imputation method of missing values; (III) a casewise robust dimensionality reduction; (IV) a monitoring strategy for the multivariate functional quality characteristic. An extensive Monte Carlo simulation study is performed to compare the RoMFCC with competing monitoring schemes already appeared in the literature. Finally, a motivating real-case study is presented where the proposed framework is used to monitor a resistance spot welding process in the automotive industry.",Christian Capezza|Fabio Centofanti|Antonio Lepore|Biagio Palumbo,,https://arxiv.org/abs/2207.07978v3,https://arxiv.org/pdf/2207.07978v3,https://doi.org/10.1080/00401706.2024.2327346,,,10.1080/00401706.2024.2327346,stat.AP,stat.AP|stat.ME,https://arxiv.org/pdf/2207.07978v3.pdf
2205.15422v2,2022-05-30T20:39:24Z,2024-11-06 17:37:23,Profile Monitoring via Eigenvector Perturbation,"In Statistical Process Control, control charts are often used to detect undesirable behavior of sequentially observed quality characteristics. Designing a control chart with desirably low False Alarm Rate (FAR) and detection delay ($ARL_1$) is an important challenge especially when the sampling rate is high and the control chart has an In-Control Average Run Length, called $ARL_0$, of 200 or more, as commonly found in practice. Unfortunately, arbitrary reduction of the FAR typically increases the $ARL_1$. Motivated by eigenvector perturbation theory, we propose the Eigenvector Perturbation Control Chart for computationally fast nonparametric profile monitoring. Our simulation studies show that it outperforms the competition and achieves both $ARL_1 \approx 1$ and $ARL_0 > 10^6$.",Takayuki Iguchi|Andrés F. Barrientos|Eric Chicken|Debajyoti Sinha,,https://arxiv.org/abs/2205.15422v2,https://arxiv.org/pdf/2205.15422v2,,"Main: 19 pages, 3 figures. Supplemental: 24 pages, 9 figures This article has been accepted for publication in Technometrics, published by Taylor & Francis",,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2205.15422v2.pdf
2205.10447v2,2022-05-20T21:46:46Z,2022-06-02 03:48:26,Hot-spots Detection in Count Data by Poisson Assisted Smooth Sparse Tensor Decomposition,"Count data occur widely in many bio-surveillance and healthcare applications, e.g., the numbers of new patients of different types of infectious diseases from different cities/counties/states repeatedly over time, say, daily/weekly/monthly. For this type of count data, one important task is the quick detection and localization of hot-spots in terms of unusual infectious rates so that we can respond appropriately. In this paper, we develop a method called Poisson assisted Smooth Sparse Tensor Decomposition (PoSSTenD), which not only detects when hot-spots occur but also localizes where hot-spots occur. The main idea of our proposed PoSSTenD method is articulated as follows. First, we represent the observed count data as a three-dimensional tensor including (1) a spatial dimension for location patterns, e.g., different cities/countries/states; (2) a temporal domain for time patterns, e.g., daily/weekly/monthly; (3) a categorical dimension for different types of data sources, e.g., different types of diseases. Second, we fit this tensor into a Poisson regression model, and then we further decompose the infectious rate into two components: smooth global trend and local hot-spots. Third, we detect when hot-spots occur by building a cumulative sum (CUSUM) control chart and localize where hot-spots occur by their LASSO-type sparse estimation. The usefulness of our proposed methodology is validated through numerical simulation studies and a real-world dataset, which records the annual number of 10 different infectious diseases from 1993 to 2018 for 49 mainland states in the United States.",Yujie Zhao|Xiaoming Huo|Yajun Mei,,https://arxiv.org/abs/2205.10447v2,https://arxiv.org/pdf/2205.10447v2,https://doi.org/10.1080/02664763.2022.2112557,"7 figures, 22 pages, 4 tables","Journal of Applied Statistics, 2022",10.1080/02664763.2022.2112557,stat.AP,stat.AP,https://arxiv.org/pdf/2205.10447v2.pdf
2205.02024v1,2022-05-04T12:25:33Z,2022-05-04 12:25:33,Angular Control Charts: A New Perspective for Monitoring Reliability of Multi-State Systems,"Control charts, as had been used traditionally for quality monitoring, were applied alternatively to monitor systems' reliability. In other words, they can be applied to detect changes in the failure behavior of systems. Such purpose imposed modifying traditional control charts in addition to developing charts that are more compatible with reliability monitoring. The latter developed category is known as probability limits control charts. The existing reliability monitoring control charts were only dedicated to binary-state systems, and they can't be used to monitor several states simultaneously. Therefore, this paper develops a design of control charts that accommodates multi-state systems, called here as the Angular Control Chart, which represents a new version of the probability limits control charts. This design is able to monitor state transitions simultaneously and individually in addition. Illustrative system examples are implemented to explore the monitoring procedure of the new design and to demonstrate its efficiency, effectiveness, and limitations.",Khaled Janada|Hassan Soltan|Mohamed-Sobeih Hussein|Ahmad Abdel-Shafi,,https://arxiv.org/abs/2205.02024v1,https://arxiv.org/pdf/2205.02024v1,https://doi.org/10.1016/j.cie.2022.108621,18 pages; 13 figures,Computers & Industrial Engineering 172PA (2022) 108621,10.1016/j.cie.2022.108621,stat.AP,stat.AP|eess.SY,https://arxiv.org/pdf/2205.02024v1.pdf
2203.15438v1,2022-03-29T11:11:33Z,2022-03-29 11:11:33,Anomaly Detection for Compositional Data using VSI MEWMA control chart,"In recent years, the monitoring of compositional data using control charts has been investigated in the Statistical Process Control field. In this study, we will design a Phase II Multivariate Exponentially Weighted Moving Average (MEWMA) control chart with variable sampling intervals to monitor compositional data based on isometric log-ratio transformation. The Average Time to Signal will be computed based on the Markov chain approach to investigate the performance of proposed chart. We also propose an optimal procedure to obtain the optimal control limit, smoothing constant, and out-of-control Average Time to Signal for different shift sizes and short sampling intervals. The performance of proposed chart in comparison with the standard MEWMA chart for monitoring compositional data is also provided. Finally, we end the paper with a conclusion and some recommendations for future research.",Thi Thuy Van Nguyen|Cédric Heuchenne|Kim Phuc Tran,,https://arxiv.org/abs/2203.15438v1,https://arxiv.org/pdf/2203.15438v1,,"This paper was submitted to the ""10th IFAC Conference on Manufacturing Modelling, Management and Control, Nantes, France, June 22-24, 2022"" on 14/02/2022",,,stat.AP,stat.AP,https://arxiv.org/pdf/2203.15438v1.pdf
2203.03384v1,2022-03-07T13:42:36Z,2022-03-07 13:42:36,A New $p$-Control Chart with Measurement Error Correction,"Control charts are important tools to monitor quality of products. One of useful applications is to monitor the proportion of non-conforming products. However, in practical applications, measurement error is ubiquitous and may occur due to false records or misclassification, which makes the observed proportion different from the underlying true proportion. It is also well-known that ignoring measurement error effects provides biases, and is expected that the resulting control charts may incur wrong detection. In this paper, we study this important problem and propose a valid method to correct for measurement error effects and obtain error-eliminated control chart for the proportion of non-conforming products. In addition, unlike traditional approaches, the corrected EWMA $p$-control chart provides asymmetric control limits and is flexible to handle the data with small sample size. Numerical results are conducted to justify the validity of the corrected EWMA $p$-control chart and verify the necessity of measurement error correction.",Li-Pang Chen|Su-Fen Yang,,https://arxiv.org/abs/2203.03384v1,https://arxiv.org/pdf/2203.03384v1,,"30 pages, 4 figures, 9 tables",,,stat.ME,stat.ME,https://arxiv.org/pdf/2203.03384v1.pdf
2201.12318v2,2022-01-26T19:16:51Z,2022-02-10 23:11:08,Effect of Measurement Errors on the Multivariate CUSUM CoDa Control Chart for the Manufacturing Process,"Control charts, one of the main tools in Statistical Process Control (SPC), have been widely adopted in manufacturing sectors as an effective strategy for malfunction detection throughout the previous decades. Measurement errors (M.E's) are involved in the quality characteristic of interest. The authors explored the impact of a linear covariate error model on the multivariate cumulative sum (CUSUM) control charts for a specific kind of data known as compositional data(CoDa). The average run length ARL is used to assess the performance of the proposed chart. The results indicate that M.E's significantly affects the multivariate CUSUM-CoDa control charts. The authors have used the Markov chain method to study the impact of different involved parameters using four different cases for the variance-covariance matrix (i.e. uncorrelated with equal variances, negatively correlated with equal variances, uncorrelated with unequal variances, positively correlated with unequal variances). The authors concluded that the ARL of the multivariate CUSUM-CoDa chart increase with an increase in the value of error variance-covariance matrix, while the ARL decreases with an increase in the subgroup size m or the constant powering b. For the implementation of the proposal, two illustrated examples have been reported for multivariate CUSUM-CoDa control charts in the presence of M.E's. One deals with the manufacturing process of uncoated aspirin tablets, and the other is based on monitoring machines in the muesli manufacturing process.",Muhammad Imran|Jinsheng Sun|Fatima Sehar Zaidi|Zameer Abbas|Hafiz Zafar Nazir,,https://arxiv.org/abs/2201.12318v2,https://arxiv.org/pdf/2201.12318v2,,I want to withdraw my paper because the model of the paper is not appropriate,,,stat.OT,stat.OT,https://arxiv.org/pdf/2201.12318v2.pdf
2112.09077v1,2021-12-15T10:13:26Z,2021-12-15 10:13:26,Simultaneous Monitoring of a Large Number of Heterogeneous Categorical Data Streams,"This article proposes a powerful scheme to monitor a large number of categorical data streams with heterogeneous parameters or nature. The data streams considered may be either nominal with a number of attribute levels or ordinal with some natural order among their attribute levels, such as good, marginal, and bad. For an ordinal data stream, it is assumed that there is a corresponding latent continuous data stream determining it. Furthermore, different data streams may have different number of attribute levels and different values of level probabilities. Due to high dimensionality, traditional multivariate categorical control charts cannot be applied. Here we integrate the local exponentially weighted likelihood ratio test statistics from each single stream, regardless of nominal or ordinal, into a powerful goodness-of-fit test by some normalization procedure. A global monitoring statistic is proposed ultimately. Simulation results have demonstrated the robustness and efficiency of our method.",Kaizong Bai|Jian Li,,https://arxiv.org/abs/2112.09077v1,https://arxiv.org/pdf/2112.09077v1,,,,,stat.ME,stat.ME|math.ST,https://arxiv.org/pdf/2112.09077v1.pdf
2112.05940v1,2021-12-11T09:52:44Z,2021-12-11 09:52:44,"A Note on the Moments of Special Mixture Distributions, with Applications for Control Charts","Control charts can be applied in a wide range of areas, this paper focuses on generalisations suitable for healthcare applications. We concentrate on the effect of using mixture distributions as the possible shifts in the process mean value. We give a closed formula for the expected squared deviation from the target value between samplings. This observation can be utilised in finding the cost-optimal parameters of the control chart.",Balázs Dobi|András Zempléni,,https://arxiv.org/abs/2112.05940v1,https://arxiv.org/pdf/2112.05940v1,,9 pages,,,stat.AP,stat.AP,https://arxiv.org/pdf/2112.05940v1.pdf
2112.02641v1,2021-12-05T18:07:25Z,2021-12-05 18:07:25,Another look at synthetic-type control charts,"During the last two decades, in statistical process monitoring plentiful new methods appeared with synthetic-type control charts being a prominent constituent. These charts became popular designs for several reasons. The two most important ones are simplicity and proclaimed excellent change point detection performance. Whereas there is no doubt about the former, we deal here with the latter. We will demonstrate that their performance is questionable. Expanding on some previous skeptical articles we want to critically reflect upon recently developed variants of synthetic-type charts in order to emphasize that there is little reason to apply and to push this special class of control charts.",Sven Knoth,,https://arxiv.org/abs/2112.02641v1,https://arxiv.org/pdf/2112.02641v1,,"23 pages, 56 figures, 4 tables",,,stat.ME,stat.ME,https://arxiv.org/pdf/2112.02641v1.pdf
2111.02653v2,2021-11-04T06:31:35Z,2021-12-16 04:20:30,Robust Online Detection in Serially Correlated Directed Network,"As the complexity of production processes increases, the diversity of data types drives the development of network monitoring technology. This paper mainly focuses on an online algorithm to detect serially correlated directed networks robustly and sensitively. First, we consider a transition probability matrix to resolve the double correlation of primary data. Further, since the sum of each row of the transition probability matrix is one, it standardizes the data, facilitating subsequent modeling. Then we extend the spring length based method to the multivariate case and propose an adaptive cumulative sum (CUSUM) control chart on the strength of a weighted statistic to monitor directed networks. This novel approach assumes only that the process observation is associated with nearby points without any parametric time series model, which is in line with reality. Simulation results and a real example from metro transportation demonstrate the superiority of our design.",Miaomiao Yu|Yuhao Zhou|Fugee Tsung,,https://arxiv.org/abs/2111.02653v2,https://arxiv.org/pdf/2111.02653v2,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2111.02653v2.pdf
2110.13696v2,2021-10-26T13:32:18Z,2023-01-23 10:08:36,On Monitoring High-Dimensional Processes with Individual Observations,"Modern data collecting methods and computation tools have made it possible to monitor high-dimensional processes. In this article, Phase II monitoring of high-dimensional processes is investigated when the available number of samples collected in Phase I is limitted in comparison to the number of variables. A new charting statistic for high-dimensional multivariate processes based on the diagonal elements of the underlying covariance matrix is introduced and a unified procedure for Phase I and II by employing a self-starting control chart is proposed. To remedy the effect of outliers, we adopt a robust procedure for parameter estimation in Phase I and introduce the appropriate consistent estimators. The statistical performance of the proposed method is evaluated in Phase II through average run length (ARL) criterion in the absence and presence of outliers and reveals that the proposed control chart scheme effectively detects various kinds of shifts in the process mean. Finally, we illustrate the applicability of our proposed method via a real-world example.",Mohsen Ebadi|Shojaeddin Chenouri|Stefan H. Steiner,,https://arxiv.org/abs/2110.13696v2,https://arxiv.org/pdf/2110.13696v2,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2110.13696v2.pdf
2110.13689v2,2021-10-26T13:27:57Z,2022-12-29 16:37:20,Phase I Analysis of High-Dimensional Processes in the Presence of Outliers,"One of the significant challenges in monitoring the quality of products today is the high dimensionality of quality characteristics. In this paper, we address Phase I analysis of high-dimensional processes with individual observations when the available number of samples collected over time is limited. Using a new charting statistic, we propose a robust procedure for parameter estimation in Phase I. This robust procedure is efficient in parameter estimation in the presence of outliers or contamination in the data. A consistent estimator is proposed for parameter estimation and a finite sample correction coefficient is derived and evaluated through simulation. We assess the statistical performance of the proposed method in Phase I in terms of the probability of signal criterion. This assessment is carried out in the absence and presence of outliers. We show that, in both phases, the proposed control chart scheme effectively detects various kinds of shifts in the process mean. Besides, we present two real-world examples to illustrate the applicability of our proposed method.",Mohsen Ebadi|Shojaeddin Chenouri|Stefan H. Steiner,,https://arxiv.org/abs/2110.13689v2,https://arxiv.org/pdf/2110.13689v2,,,,,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/2110.13689v2.pdf
2110.10680v1,2021-10-20T17:49:40Z,2021-10-20 17:49:40,"A Critique of a Variety of ""Memory-Based'' Process Monitoring Methods","Many extensions and modifications have been made to standard process monitoring methods such as the exponentially weighted moving average (EWMA) chart and the cumulative sum (CUSUM) chart. In addition, new schemes have been proposed based on alternative weighting of past data, usually to put greater emphasis on past data and less weight on current and recent data. In other cases, the output of one process monitoring method, such as the EWMA statistic, is used as the input to another method, such as the CUSUM chart. Often the recursive formula for a control chart statistic is itself used recursively to form a new control chart statistic. We find the use of these ad hoc methods to be unjustified. Statistical performance comparisons justifying the use of these methods have been either flawed by focusing only on zero-state run length metrics or by making comparisons to an unnecessarily weak competitor.",Sven Knoth|Nesma A. Saleh|Mahmoud A. Mahmoud|William H. Woodall|Victor G. Tercero-Gomez,,https://arxiv.org/abs/2110.10680v1,https://arxiv.org/pdf/2110.10680v1,,"31 pages, 26 figures, 10 tables",,,stat.ME,stat.ME,https://arxiv.org/pdf/2110.10680v1.pdf
2109.00952v1,2021-09-02T13:53:22Z,2021-09-02 13:53:22,Fault detection and diagnosis of batch process using dynamic ARMA-based control charts,"A wide range of approaches for batch processes monitoring can be found in the literature. This kind of process generates a very peculiar data structure, in which successive measurements of many process variables in each batch run are available. Traditional approaches do not take into account the time series nature of the data. The main reason is that the time series inference theory is not based on replications of time series, as it is in batch process data. It is based on the variability in a time domain. This fact demands some adaptations of this theory in order to accommodate the model coefficient estimates, considering jointly the batch to batch samples variability (batch domain) and the serial correlation in each batch (time domain). In order to address this issue, this paper proposes a new approach grounded in a group of control charts based on the classical ARMA model for monitoring and diagnostic of batch processes dynamics. The model coefficients are estimated (through the ordinary least square method) for each historical time series sample batch and modified Hotelling and t-Student distributions are derived and used to accommodate those estimates. A group of control charts based on that distributions are proposed for monitoring the new batches. Additionally, those groups of charts help to fault diagnosis, identifying the source of disturbances. Through simulated and real data we show that this approach seems to work well for both purposes.",Batista Nunes de Oliveira|Marcio Valk|Danilo Marcondes Filho,,https://arxiv.org/abs/2109.00952v1,https://arxiv.org/pdf/2109.00952v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2109.00952v1.pdf
2108.05239v1,2021-08-11T14:15:59Z,2021-08-11 14:15:59,The Effect of Autocorrelation on the Shewhart-RZ Control Chart,"In many industrial manufacturing processes, the quality of products depends on the relation between two main ingredients or characteristics. Often, this calls for monitoring the ratio of two normal random variables with statistical process control (SPC) techniques. A large number of studies related to designing control charts monitoring this ratio have been published. However, these studies are based purely on the assumption of independent observations. In practice, autocorrelation between observations can exist and should be modeled to protect against the false alarm rate inflation when implementing a control chart. In this paper, we tackle this problem by investigating the performance of the Shewhart control chart monitoring the ratio of two normal variables, (denoted as Shewhart-RZ), in the presence of autocorrelation between successive observations. The autocorrelation is modeled through the bivariate autoregressive model VAR(1). We also provide an example to illustrates the use of the Shewhart-RZ control chart on a quality control problem.",H. D. Nguyen|A. Ahmadi Nadi|K. P. Tran|P. Castagliola|G. Celano|K. D. Tran,,https://arxiv.org/abs/2108.05239v1,https://arxiv.org/pdf/2108.05239v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2108.05239v1.pdf
2107.13394v1,2021-07-14T18:01:46Z,2021-07-14 18:01:46,Nonlinear State Space Modeling and Control of the Impact of Patients' Modifiable Lifestyle Behaviors on the Emergence of Multiple Chronic Conditions,"The emergence and progression of multiple chronic conditions (MCC) over time often form a dynamic network that depends on patient's modifiable risk factors and their interaction with non-modifiable risk factors and existing conditions. Continuous time Bayesian networks (CTBNs) are effective methods for modeling the complex network of MCC relationships over time. However, CTBNs are not able to effectively formulate the dynamic impact of patient's modifiable risk factors on the emergence and progression of MCC. Considering a functional CTBN (FCTBN) to represent the underlying structure of the MCC relationships with respect to individuals' risk factors and existing conditions, we propose a nonlinear state-space model based on Extended Kalman filter (EKF) to capture the dynamics of the patients' modifiable risk factors and existing conditions on the MCC evolution over time. We also develop a tensor control chart to dynamically monitor the effect of changes in the modifiable risk factors of individual patients on the risk of new chronic conditions emergence. We validate the proposed approach based on a combination of simulation and real data from a dataset of 385 patients from Cameron County Hispanic Cohort (CCHC) over multiple years. The dataset examines the emergence of 5 chronic conditions (Diabetes, Obesity, Cognitive Impairment, Hyperlipidemia, and Hypertension) based on 4 modifiable risk factors representing lifestyle behaviors (Diet, Exercise, Smoking Habit, and Drinking Habit) and 3 non-modifiable risk factors, including demographic information (Age, Gender, Education). The results demonstrate the effectiveness of the proposed methodology for dynamic prediction and monitoring of the risk of MCC emergence in individual patients.",Syed Hasib Akhter Faruqui|Adel Alaeddini|Jing Wang|Susan P Fisher-Hoch|Joseph B Mccormic,,https://arxiv.org/abs/2107.13394v1,https://arxiv.org/pdf/2107.13394v1,,Submitted to IEEE Access for review,,,stat.ME,stat.ME|cs.LG|eess.SY|stat.AP,https://arxiv.org/pdf/2107.13394v1.pdf
2107.00224v1,2021-07-01T05:42:44Z,2021-07-01 05:42:44,The Case against Generally Weighted Moving Average (GWMA) Control Charts,"We argue against the use of generally weighted moving average (GWMA) control charts. Our primary reasons are the following: 1) There is no recursive formula for the GWMA control chart statistic, so all previous data must be stored and used in the calculation of each chart statistic. 2) The Markovian property does not apply to the GWMA statistics, so computer simulation must be used to determine control limits and the statistical performance. 3) An appropriately designed, and much simpler, exponentially weighted moving average (EWMA) chart provides as good or better statistical performance. 4) In some cases the GWMA chart gives more weight to past data values than to current values.",Sven Knoth|William H. Woodall|Víctor G. Tercero-Gómez,,https://arxiv.org/abs/2107.00224v1,https://arxiv.org/pdf/2107.00224v1,https://doi.org/10.1080/08982112.2021.2002359,"8 pages, 8 figures, 2 tables",,10.1080/08982112.2021.2002359,stat.ME,stat.ME,https://arxiv.org/pdf/2107.00224v1.pdf
2102.00375v1,2021-01-31T04:29:56Z,2021-01-31 04:29:56,Real-time Monitoring of Autonomous Vehicle's Time Gap Variations: A Bayesian Framework,"This paper proposes a novel monitoring methodology for car-following control of automated vehicles that uses real-time measurements of spacing and velocity obtained through vehicle sensors. This study focuses on monitoring the time gap, a key parameter that dictates the desired following spacing of the controlled vehicle. The goal is to monitor deviations in actual time gap from a desired setting and detect when it deviates beyond a control limit. A random coefficient modeling is developed to systematically capture the stochastic distribution of the time gap and derive a closed-form Bayesian updating scheme for real-time inference. A control chart is then adopted to systematically set the control limits and inform when the time gap setting should be changed. Simulation experiments are performed to demonstrate the effectiveness of the proposes method for monitoring the time gap and alerting when the parameter setting needs to be changed.",Wissam Kontar|Soyoung Ahn,,https://arxiv.org/abs/2102.00375v1,https://arxiv.org/pdf/2102.00375v1,,"This paper was accepted to the 99th Annual Meeting of the Transportation Research Board, Washington, D.C., United States, 2020",,,eess.SY,eess.SY,https://arxiv.org/pdf/2102.00375v1.pdf
2101.11711v1,2021-01-25T21:56:33Z,2021-01-25 21:56:33,Damage detection in operational wind turbine blades using a new approach based on machine learning,"The application of reliable structural health monitoring (SHM) technologies to operational wind turbine blades is a challenging task, due to the uncertain nature of the environments they operate in. In this paper, a novel SHM methodology, which uses Gaussian Processes (GPs) is proposed. The methodology takes advantage of the fact that the blades on a turbine are nominally identical in structural properties and encounter the same environmental and operational variables (EOVs). The properties of interest are the first edgewise frequencies of the blades. The GPs are used to predict the edge frequencies of one blade given that of another, after these relationships between the pairs of blades have been learned when the blades are in a healthy state. In using this approach, the proposed SHM methodology is able to identify when the blades start behaving differently from one another over time. To validate the concept, the proposed SHM system is applied to real onshore wind turbine blade data, where some form of damage was known to have taken place. X-bar control chart analysis of the residual errors between the GP predictions and actual frequencies show that the system successfully identified early onset of damage as early as six months before it was identified and remedied.",Kartik Chandrasekhar|Nevena Stevanovic|Elizabeth J. Cross|Nikolaos Dervilis|Keith Worden,,https://arxiv.org/abs/2101.11711v1,https://arxiv.org/pdf/2101.11711v1,https://doi.org/10.1016/j.renene.2020.12.119,,"This is an author produced version of a paper subsequently published in Renewable Energy, Elsevier, 2021. Uploaded in accordance with the publisher's self-archiving policy",10.1016/j.renene.2020.12.119,cs.LG,cs.LG|physics.data-an,https://arxiv.org/pdf/2101.11711v1.pdf
2101.09424v1,2021-01-23T05:38:17Z,2021-01-23 05:38:17,A Change-Point Based Control Chart for Detecting Sparse Changes in High-Dimensional Heteroscedastic Data,"Because of the curse-of-dimensionality, high-dimensional processes present challenges to traditional multivariate statistical process monitoring (SPM) techniques. In addition, the unknown underlying distribution and complicated dependency among variables such as heteroscedasticity increase uncertainty of estimated parameters, and decrease the effectiveness of control charts. In addition, the requirement of sufficient reference samples limits the application of traditional charts in high dimension low sample size scenarios (small n, large p). More difficulties appear in detecting and diagnosing abnormal behaviors that are caused by a small set of variables, i.e., sparse changes. In this article, we propose a changepoint based control chart to detect sparse shifts in the mean vector of high-dimensional heteroscedastic processes. Our proposed method can start monitoring when the number of observations is a lot smaller than the dimensionality. The simulation results show its robustness to nonnormality and heteroscedasticity. A real data example is used to illustrate the effectiveness of the proposed control chart in high-dimensional applications. Supplementary material and code are provided online.",Zezhong Wang|Inez Maria Zwetsloot,,https://arxiv.org/abs/2101.09424v1,https://arxiv.org/pdf/2101.09424v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/2101.09424v1.pdf
2101.07575v2,2021-01-19T11:47:51Z,2021-01-22 04:41:52,A note on the g and h control charts,"In this note, we revisit the $g$ and $h$ control charts that are commonly used for monitoring the number of conforming cases between the two consecutive appearances of nonconformities. It is known that the process parameter of these charts is usually unknown and estimated by using the maximum likelihood estimator and the minimum variance unbiased estimator. However, the minimum variance unbiased estimator in the control charts has been inappropriately used in the quality engineering literature. This observation motivates us to provide the correct minimum variance unbiased estimator and investigate theoretical and empirical biases of these estimators under consideration. Given that these charts are developed based on the underlying assumption that samples from the process should be balanced, which is often not satisfied in many practical applications, we propose a method for constructing these charts with unbalanced samples.",Chanseok Park|Min Wang,,https://arxiv.org/abs/2101.07575v2,https://arxiv.org/pdf/2101.07575v2,,"17 pages, 1 figure, 2 tables",,,stat.AP,stat.AP,https://arxiv.org/pdf/2101.07575v2.pdf
2101.04011v1,2021-01-11T16:36:37Z,2021-01-11 16:36:37,Controlling the EWMA $S^2$ control chart false alarm behavior when the in-control variance level must be estimated,"Investigating the problem of setting control limits in the case of parameter uncertainty is more accessible when monitoring the variance because only one parameter has to be estimated. Simply ignoring the induced uncertainty frequently leads to control charts with poor false alarm performances. Adjusting the unconditional in-control (IC) average run length (ARL) makes the situation even worse. Guaranteeing a minimum conditional IC ARL with some given probability is another very popular approach to solving these difficulties. However, it is very conservative as well as more complex and more difficult to communicate. We utilize the probability of a false alarm within the planned number of points to be plotted on the control chart. It turns out that adjusting this probability produces notably different limit adjustments compared to controlling the unconditional IC ARL. We then develop numerical algorithms to determine the respective modifications of the upper and two-sided exponentially weighted moving average (EWMA) charts based on the sample variance for normally distributed data. These algorithms are made available within an R package. Finally, the impacts of the EWMA smoothing constant and the size of the preliminary sample on the control chart design and its performance are studied.",Sven Knoth,,https://arxiv.org/abs/2101.04011v1,https://arxiv.org/pdf/2101.04011v1,https://doi.org/10.1002/asmb.2613,,,10.1002/asmb.2613,stat.ME,stat.ME,https://arxiv.org/pdf/2101.04011v1.pdf
2012.14759v5,2020-12-29T14:15:20Z,2024-01-24 06:46:48,Dependence control chart using maximum copula entropy,"Statistical quality control methods are noteworthy to producing standard production in manufacturing processes. In this regard, there are many classical manners to control the process. Many of them have a global assumption around the distributions of the process data. They are supposed to be Normal, but it is clear that it is not always valid for all processes. Such control charts made some wrong decisions that waste funds. So, the main question while working with multivariate data set is how to find the multivariate distribution of the data set, which saves the original dependency between variables. To our knowledge, a copula function guarantees dependence on the result function. It is not enough when there is no other fundamental information about the statistical society, and we have just a data set. Therefore, we apply the maximum entropy concept to deal with this situation. In this paper, first of all, we get the joint distribution of a data set from a manufacturing process that needs to be in-control while running the production process. Then, we get an elliptical control limit via the maximum copula entropy. Finally, we represent a practical example using the method. Average run lengths are calculated for some means and shifts to show the ability of the maximum copula entropy. In the end, two practical data examples are presented, and the results of our method are compared with the traditional way based on Fisher distribution.",Seyedeh Azadeh Fallah Mortezanejad|Ruochen Wang|Gholamreza Mohtashami Borzadaran|Kim Phuc Tran,,https://arxiv.org/abs/2012.14759v5,https://arxiv.org/pdf/2012.14759v5,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2012.14759v5.pdf
2012.14289v4,2020-12-28T15:34:05Z,2023-11-01 02:31:37,Profile control chart based on maximum entropy,"Monitoring a process over time is so important in manufacturing processes to reduce the waste of money and time. Some charts as Shewhart, CUSUM, and EWMA are common to monitor a process with a single intended attribute which is used in different kinds of processes with various ranges of shifts. In some cases, the process quality is characterized by different types of profiles. The purpose of this article is to monitor profile coefficients instead of a process mean. In this paper, two methods are proposed for monitoring the intercept and slope of the simple linear profile, simultaneously. In this regard, two methods are compared here. The first one is the linear regression, and the one is the maximum entropy principle. The T2 Hotelling statistics is used to transfer two coefficients to a scalar. A simulation study is applied to compare the two methods in terms of the second type of error and average run length. Finally, two real examples are presented to demonstrate the applicability of the proposed chart. The first one is about semiconductors, and the second one is about pharmaceutical production processes. The performance of the methods is relatively similar. The maximum entropy plays an important role in correctly identifying differences in the pharmaceutical example, while linear regression did not correctly detect these changes.",Seyedeh Azadeh Fallah Mortezanejad|Ruochen Wang|Gholamreza Mohtashami Borzadaran|Renkai Ding|Kim Phuc Tran,,https://arxiv.org/abs/2012.14289v4,https://arxiv.org/pdf/2012.14289v4,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/2012.14289v4.pdf
2011.06080v1,2020-11-10T17:15:53Z,2020-11-10 17:15:53,Statistical learning for change point and anomaly detection in graphs,"Complex systems which can be represented in the form of static and dynamic graphs arise in different fields, e.g. communication, engineering and industry. One of the interesting problems in analysing dynamic network structures is to monitor changes in their development. Statistical learning, which encompasses both methods based on artificial intelligence and traditional statistics, can be used to progress in this research area. However, the majority of approaches apply only one or the other framework. In this paper, we discuss the possibility of bringing together both disciplines in order to create enhanced network monitoring procedures focussing on the example of combining statistical process control and deep learning algorithms. Together with the presentation of change point and anomaly detection in network data, we propose to monitor the response times of ambulance services, applying jointly the control chart for quantile function values and a graph convolutional network.",Anna Malinovskaya|Philipp Otto|Torben Peters,,https://arxiv.org/abs/2011.06080v1,https://arxiv.org/pdf/2011.06080v1,,,,,cs.LG,cs.LG|stat.ME,https://arxiv.org/pdf/2011.06080v1.pdf
2010.11826v1,2020-10-22T16:03:58Z,2020-10-22 16:03:58,Nonparametric robust monitoring of time series panel data,"In many applications, a control procedure is required to detect potential deviations in a panel of serially correlated processes. It is common that the processes are corrupted by noise and that no prior information about the in-control data are available for that purpose. This paper suggests a general nonparametric monitoring scheme for supervising such a panel with time-varying mean and variance. The method is based on a control chart designed by block bootstrap, which does not require parametric assumptions on the distribution of the data. The procedure is tailored to cope with strong noise, potentially missing values and absence of in-control series, which is tackled by an intelligent exploitation of the information in the panel. Our methodology is completed by support vector machine procedures to estimate magnitude and form of the encountered deviations (such as stepwise shifts or functional drifts). This scheme, though generic in nature, is able to treat an important applied data problem: the control of deviations in a subset of sunspot number observations which are part of the International Sunspot Number, a world reference for long-term solar activity.",Sophie Mathieu|Rainer von Sachs|Véronique Delouille|Laure Lefèvre|Christian Ritter,,https://arxiv.org/abs/2010.11826v1,https://arxiv.org/pdf/2010.11826v1,,"58 pages, 18 figures",,,stat.AP,stat.AP|stat.ME,https://arxiv.org/pdf/2010.11826v1.pdf
2010.09398v2,2020-10-19T11:36:24Z,2021-05-14 15:39:17,Online network monitoring,"The application of network analysis has found great success in a wide variety of disciplines; however, the popularity of these approaches has revealed the difficulty in handling networks whose complexity scales rapidly. One of the main interests in network analysis is the online detection of anomalous behaviour. To overcome the curse of dimensionality, we introduce a network surveillance method bringing together network modelling and statistical process control. Our approach is to apply multivariate control charts based on exponential smoothing and cumulative sums in order to monitor networks determined by temporal exponential random graph models (TERGM). This allows us to account for temporal dependence, while simultaneously reducing the number of parameters to be monitored. The performance of the proposed charts is evaluated by calculating the average run length for both simulated and real data. To prove the appropriateness of the TERGM to describe network data, some measures of goodness of fit are inspected. We demonstrate the effectiveness of the proposed approach by an empirical application, monitoring daily flights in the United States to detect anomalous patterns.",Anna Malinovskaya|Philipp Otto,,https://arxiv.org/abs/2010.09398v2,https://arxiv.org/pdf/2010.09398v2,https://doi.org/10.1007/s10260-021-00589-z,,Statistical Methods & Applications 2021,10.1007/s10260-021-00589-z,stat.ME,stat.ME,https://arxiv.org/pdf/2010.09398v2.pdf
2010.09099v1,2020-10-18T20:45:14Z,2020-10-18 20:45:14,Decentralized and Secure Generation Maintenance with Differential Privacy,"Decentralized methods are gaining popularity for data-driven models in power systems as they offer significant computational scalability while guaranteeing full data ownership by utility stakeholders. However, decentralized methods still require sharing information about network flow estimates over public facing communication channels, which raises privacy concerns. In this paper we propose a differential privacy driven approach geared towards decentralized formulations of mixed integer operations and maintenance optimization problems that protects network flow estimates. We prove strong privacy guarantees by leveraging the linear relationship between the phase angles and the flow. To address the challenges associated with the mixed integer and dynamic nature of the problem, we introduce an exponential moving average based consensus mechanism to enhance convergence, coupled with a control chart based convergence criteria to improve stability. Our experimental results obtained on the IEEE 118 bus case demonstrate that our privacy preserving approach yields solution qualities on par with benchmark methods without differential privacy. To demonstrate the computational robustness of our method, we conduct experiments using a wide range of noise levels and operational scenarios.",Paritosh Ramanan|Murat Yildirim|Nagi Gebraeel|Edmond Chow,,https://arxiv.org/abs/2010.09099v1,https://arxiv.org/pdf/2010.09099v1,,,,,cs.DC,cs.DC|cs.CR|math.OC,https://arxiv.org/pdf/2010.09099v1.pdf
2010.02968v4,2020-10-06T18:49:51Z,2023-10-18 08:19:30,Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Fréchet mean with the shape invariant model,"A modelling framework suitable for detecting shape shifts in functional profiles combining the notion of Fréchet mean and the concept of deformation models is developed and proposed. The generalized mean sense offered by the Fréchet mean notion is employed to capture the typical pattern of the profiles under study, while the concept of deformation models, and in particular of the shape invariant model, allows for interpretable parameterizations of profile's deviations from the typical shape. EWMA-type control charts compatible with the functional nature of data and the employed deformation model are built and proposed, exploiting certain shape characteristics of the profiles under study with respect to the generalized mean sense, allowing for the identification of potential shifts concerning the shape and/or the deformation process. Potential shifts in the shape deformation process, are further distinguished to significant shifts with respect to amplitude and/or the phase of the profile under study. The proposed modelling and shift detection framework is implemented to a real world case study, where daily concentration profiles concerning air pollutants from an area in the city of Athens are modelled, while profiles indicating hazardous concentration levels are successfully identified in most of the cases.",Georgios I. Papayiannis|Stelios Psarakis|Athanasios N. Yannacopoulos,,https://arxiv.org/abs/2010.02968v4,https://arxiv.org/pdf/2010.02968v4,https://doi.org/10.3390/math11214466,"23 pages, 7 figures","Mathematics 2023, 11, 4466",10.3390/math11214466,stat.ME,stat.ME|cs.LG|stat.ML,https://arxiv.org/pdf/2010.02968v4.pdf
2010.01297v1,2020-10-03T07:38:21Z,2020-10-03 07:38:21,One-sided Shewhart control charts for monitoring the ratio of two normal variables in Short Production Runs,"Monitoring the ratio of two normal random variables plays an important role in several manufacturing environments. For short production runs, however, the control charts assumed infinite processes cannot function effectively to detect anomalies. In this paper, we tackle this problem by proposing two one-sided Shewhart-type charts to monitor the ratio of two normal random variables for an infinite horizon production. The statistical performance of the proposed charts is investigated using the truncated average run length as a performance measure in short production runs. In order to help the quality practitioner to implement these control charts, we have provided ready-to-use tables of the control limit parameters. An illustrative example from the food industry is given for illustration.",K. D. Tran|Q. U. A Khaliq|A. A. Nadi|H Tran|K. P. Tran,,https://arxiv.org/abs/2010.01297v1,https://arxiv.org/pdf/2010.01297v1,,,,,stat.AP,stat.AP|math.NA|stat.CO,https://arxiv.org/pdf/2010.01297v1.pdf
2007.11705v2,2020-07-22T22:27:31Z,2020-08-17 01:18:30,Event-based Detection of Changes in IaaS Performance Signatures,"We propose a novel ECA approach to manage changes in IaaS performance signatures. The proposed approach relies on the detection of anomalous performance behavior in the context of IaaS performance signatures. A novel anomaly-based event detection technique is proposed. It utilizes the experience of free trial users to detect potential changes in IaaS performance signatures. A signature change detection technique is proposed using the cumulative sum control chart analysis. Additionally, a self-adjustment method is introduced to improve the accuracy of the proposed approach. A set of experiments based on real-world datasets are conducted to show the effectiveness of the proposed approach.",Sheik Mohammad Mostakim Fattah|Athman Bouguettaya,,https://arxiv.org/abs/2007.11705v2,https://arxiv.org/pdf/2007.11705v2,,"8 pages, Accepted and to appear in 2020 International Conference on Services Computing (IEEE SCC 2020). Content may change prior to final publication",,,cs.DC,cs.DC,https://arxiv.org/pdf/2007.11705v2.pdf
2007.09844v1,2020-07-20T02:29:08Z,2020-07-20 02:29:08,Bayesian EWMA and CUSUM Control Charts Under Different Loss Functions,"The Exponentially Weighted Moving Average (EWMA) and Cumulative Sum (CUSUM) control charts have been used in profile monitoring to track drift shifts that occur in a monitored process. We construct Bayesian EWMA and Bayesian CUSUM charts informed by posterior and posterior predictive distributions using different loss functions, prior distributions, and likelihood distributions. A simulation study is performed, and the performance of the charts are evaluated via average run length (ARL), standard deviation of the run length (SDRL), average time to signal (ATS), and standard deviation of time to signal (SDTS). A sensitivity analysis is conducted using choices for the smoothing parameter, out-of-control shift size, and hyper-parameters of the distribution. Based on obtained results, we provide recommendations for use of the Bayesian EWMA and Bayesian CUSUM control charts.",Chelsea Mitchell|Abdel-Salam Abdel-Salam|D'Arcy Mays,,https://arxiv.org/abs/2007.09844v1,https://arxiv.org/pdf/2007.09844v1,,"19 pages, 5 tables, 35 equations, presented at Joint Statistical Meeting (08/2020)",,,stat.ME,stat.ME,https://arxiv.org/pdf/2007.09844v1.pdf
2006.14737v1,2020-06-26T00:31:04Z,2020-06-26 00:31:04,Monitoring of process and risk-adjusted medical outcomes using a multi-stage MEWMA chart,"Most statistical process control programmes in healthcare focus on surveillance of outcomes at the final stage of a procedure, such as mortality or failure rates. Such an approach ignores the multi-stage nature of these procedures, in which a patient progresses through several stages prior to the final stage. In this paper, we develop a multi-stage control chart based on a multivariate exponentially weighted moving average (EWMA) test statistic derived from score equations. This allows simultaneous monitoring of all intermediate and final stage outcomes of a healthcare process, with adjustment for underlying patient risk factors and dependence between outcome variables. Use of the EWMA test statistics allows quick detection of small gradual changes in any part of the process. Three advantages of the approach are: better understanding of how outcomes at different stages relate to each other, explicit monitoring of upstream stage outcomes may help curtail trends that lead to poorer end-stage outcomes and understanding the impact of each stage can help determine the most effective allocation of quality improvement resources. Simulations are performed to test the control charts under various types of hypothesised shifts, and the results are summarised using out-of-control average run lengths.",Doaa Ayad|Nokuthaba Sibanda,,https://arxiv.org/abs/2006.14737v1,https://arxiv.org/pdf/2006.14737v1,,"17 pages, 3 figures Submitted to Statistical Methods in Medical Research",,,stat.ME,stat.ME|stat.OT,https://arxiv.org/pdf/2006.14737v1.pdf
2005.12585v1,2020-05-26T09:09:22Z,2020-05-26 09:09:22,Real-Time Fault Detection and Process Control Based on Multi-channel Sensor Data Fusion,"Sensor signals acquired in the industrial process contain rich information which can be analyzed to facilitate effective monitoring of the process, early detection of system anomalies, quick diagnosis of fault root causes, and intelligent system design and control. In many mechatronic systems, multiple signals are acquired by different sensor channels (i.e. multi-channel data) which can be represented by high-order arrays (tensorial data). The multi-channel data has a high-dimensional and complex cross-correlation structure. It is crucial to develop a method that considers the interrelationships between different sensor channels. This paper proposes a new process monitoring approach based on uncorrelated multilinear discriminant analysis that can effectively model the multi-channel data to achieve a superior monitoring and fault diagnosis performance compared to other competing methods. The proposed method is applied directly to the high-dimensional tensorial data. Features are extracted and combined with multivariate control charts to monitor multi-channel data. The effectiveness of the proposed method in quick detection of process changes is demonstrated with both the simulation and a real-world case study.",Feng Ye|Zhijie Xia|Min Dai|Zhisheng Zhang,,https://arxiv.org/abs/2005.12585v1,https://arxiv.org/pdf/2005.12585v1,,,,,eess.SP,eess.SP|eess.SY,https://arxiv.org/pdf/2005.12585v1.pdf
2005.06832v2,2020-05-14T09:24:07Z,2020-11-10 02:53:11,Detection of Intermittent Faults Based on an Optimally Weighted Moving Average T^2 Control Chart with Stationary Observations,"The moving average (MA)-type scheme, also known as the smoothing method, has been well established within the multivariate statistical process monitoring (MSPM) framework since the 1990s. However, its theoretical basis is still limited to smoothing independent data, and the optimality of its equally or exponentially weighted scheme remains unproven. This paper aims to weaken the independence assumption in the existing MA method, and then extend it to a broader area of dealing with autocorrelated weakly stationary processes. With the discovery of the non-optimality of the equally and exponentially weighted schemes used for fault detection when data have autocorrelation, the essence that they do not effectively utilize the correlation information of samples is revealed, giving birth to an optimally weighted moving average (OWMA) theory. The OWMA method is combined with the Hotelling's $T^2$ statistic to form an OWMA $T^2$ control chart (OWMA-TCC), in order to detect a more challenging type of fault, i.e., intermittent fault (IF). Different from the MA scheme that puts an equal weight on samples within a time window, OWMA-TCC uses correlation (autocorrelation and cross-correlation) information to find an optimal weight vector (OWV) for the purpose of IF detection (IFD). In order to achieve a best IFD performance, the concept of IF detectability is defined and corresponding detectability conditions are provided, which further serve as selection criteria of the OWV. Then, the OWV is given in the form of a solution to nonlinear equations, whose existence is proven with the aid of the Brouwer fixed-point theory. Moreover, symmetrical structure of the OWV is revealed, and the optimality of the MA scheme for any IF directions when data exhibit no autocorrelation is proven.",Yinghong Zhao|Xiao He|Junfeng Zhang|Hongquan Ji|Donghua Zhou|Michael G. Pecht,,https://arxiv.org/abs/2005.06832v2,https://arxiv.org/pdf/2005.06832v2,https://doi.org/10.1016/j.automatica.2020.109298,"Automatica, Published online, 2020",,10.1016/j.automatica.2020.109298,cs.IT,cs.IT|eess.SY,https://arxiv.org/pdf/2005.06832v2.pdf
2005.06825v2,2020-05-14T09:08:37Z,2020-08-07 01:58:27,Detection and Detectability of Intermittent Faults Based on Moving Average T2 Control Charts with Multiple Window Lengths,"So far, problems of intermittent fault (IF) detection and detectability have not been fully investigated in the multivariate statistics framework. The characteristics of IFs are small magnitudes and short durations, and consequently traditional multivariate statistical methods using only a single observation are no longer effective. Thus in this paper, moving average T^2 control charts (MA-TCCs) with multiple window lengths, which simultaneously employ a bank of MA-TCCs with different window lengths, are proposed to address the IF detection problem. Methods to reduce false/missing alarms and infer the IFs' appearing and disappearing time instances are presented. In order to analyze the detection capability for IFs, definitions of guaranteed detectability are introduced, which is an extension and generalization of the original fault detectability concept focused on permanent faults (PFs). Then, necessary and sufficient conditions are derived for the detectability of IFs, which may appear and disappear several times with different magnitudes and durations. Based on these conditions, some optimal properties of two important window lengths are further discussed. In this way, a theoretical framework for the analysis of IFs' detectability is established as well as extended discussions on how the theoretical results can be adapted to real-world applications. Finally, simulation studies on a numerical example and the continuous stirred tank reactor (CSTR) process are carried out to show the effectiveness of the developed methods.",Yinghong Zhao|Xiao He|Michael G. Pecht|Junfeng Zhang|Donghua Zhou,,https://arxiv.org/abs/2005.06825v2,https://arxiv.org/pdf/2005.06825v2,https://doi.org/10.1016/j.jprocont.2020.07.002,,"Journal of Process Control, 2020, 92: 296-309",10.1016/j.jprocont.2020.07.002,eess.SY,eess.SY,https://arxiv.org/pdf/2005.06825v2.pdf
2004.13527v1,2020-04-25T21:19:44Z,2020-04-25 21:19:44,Real-Time Anomaly Detection in Data Centers for Log-based Predictive Maintenance using an Evolving Fuzzy-Rule-Based Approach,"Detection of anomalous behaviors in data centers is crucial to predictive maintenance and data safety. With data centers, we mean any computer network that allows users to transmit and exchange data and information. In particular, we focus on the Tier-1 data center of the Italian Institute for Nuclear Physics (INFN), which supports the high-energy physics experiments at the Large Hadron Collider (LHC) in Geneva. The center provides resources and services needed for data processing, storage, analysis, and distribution. Log records in the data center is a stochastic and non-stationary phenomenon in nature. We propose a real-time approach to monitor and classify log records based on sliding time windows, and a time-varying evolving fuzzy-rule-based classification model. The most frequent log pattern according to a control chart is taken as the normal system status. We extract attributes from time windows to gradually develop and update an evolving Gaussian Fuzzy Classifier (eGFC) on the fly. The real-time anomaly monitoring system has to provide encouraging results in terms of accuracy, compactness, and real-time operation.",Leticia Decker|Daniel Leite|Luca Giommi|Daniele Bonacorsi,,https://arxiv.org/abs/2004.13527v1,https://arxiv.org/pdf/2004.13527v1,,"9 pages, 6 figures, 1 table, IEEE World Congress on Computational Intelligence (WCCI 2020). arXiv admin note: substantial text overlap with arXiv:2004.09986",,,cs.AI,cs.AI|cs.DB|cs.LG,https://arxiv.org/pdf/2004.13527v1.pdf
2002.06159v2,2020-02-14T18:18:42Z,2021-04-15 03:15:40,Statistical Monitoring of the Covariance Matrix in Multivariate Processes: A Literature Review,"Monitoring several correlated quality characteristics of a process is common in modern manufacturing and service industries. Although a lot of attention has been paid to monitoring the multivariate process mean, not many control charts are available for monitoring the covariance matrix. This paper presents a comprehensive overview of the literature on control charts for monitoring the covariance matrix in a multivariate statistical process monitoring (MSPM) framework. It classifies the research that has previously appeared in the literature. We highlight the challenging areas for research and provide some directions for future research.",Mohsen Ebadi|Shoja'eddin Chenouri|Dennis K. J. Lin|Stefan H. Steiner,,https://arxiv.org/abs/2002.06159v2,https://arxiv.org/pdf/2002.06159v2,,,,,stat.ME,stat.ME|math.ST|stat.AP,https://arxiv.org/pdf/2002.06159v2.pdf
2002.00511v1,2020-02-02T23:35:35Z,2020-02-02 23:35:35,Investigating usability of MSstatsQC software,"MSstatsQC [3] is an open-source software that provides longitudinal system suitability monitoring tools in the form of control charts for proteomic experiments. It includes simultaneous tools for the mean and dispersion of suitability metrics and presents alternative methods of monitoring through different tabs that are designed in the interface. This research focuses on investigating the usability of MSstatsQC software and the interpretability of the designed plots. In this study, we ask 4 test users, from the proteomics field, to complete a series of tasks and questionnaires. The tasks are designed to test the usability of the software in terms of importing data files, selecting appropriate metrics, guide set, and peptides, and finally creating decision rules (tasks 1 and 3 in appendix). The questionnaires ask about interpretability of the plots including control charts, box plots, heat maps, river plots, and radar plots (tasks 1 and 4 in appendix). The goal of the questions is to determine if the test users understand the plots and can interpret them. Results show limitations in usability and plot interpretability, especially in the data import section. We suggest the following modifications. I) providing conspicuous guides close to the window related to up-loading a datafile as well as providing error messages that pop-up when the data set has a wrong format II) providing plot descriptions, hints to interpret plots, plot titles and appropriate axis labels, and, III) Numbering tabs to show the flow of procedures in the software.",Sara Mohammad Taheri|Omkar Terse|Eralp Dogu|Magy Seif El-Nasr|Olga Vitek,,https://arxiv.org/abs/2002.00511v1,https://arxiv.org/pdf/2002.00511v1,,19 pages,,,cs.HC,cs.HC,https://arxiv.org/pdf/2002.00511v1.pdf
2001.01821v1,2020-01-07T00:23:40Z,2020-01-07 00:23:40,Monitoring Coefficient of Variation using One-Sided Run Rules control charts in the presence of Measurement Errors,"We investigate in this paper the effect of the measurement error on the performance of Run Rules control charts monitoring the coefficient of variation (CV) squared. The previous Run Rules CV chart in the literature is improved slightly by monitoring the CV squared using two one-sided Run Rules charts instead of monitoring the CV itself using a two-sided chart. The numerical results show that this improvement gives better performance in detecting process shifts. Moreover, we will show through simulation that the \textit{precision} and \textit{accuracy} errors do have negative effect on the performance of the proposed Run Rules charts. We also find out that taking multiple measurements per item is not an effective way to reduce these negative effects.",P. H. Tran|C. Heuchenne|H. D. Nguyen,,https://arxiv.org/abs/2001.01821v1,https://arxiv.org/pdf/2001.01821v1,,"23 pages, 8 figures, 8 tables",,,stat.CO,stat.CO,https://arxiv.org/pdf/2001.01821v1.pdf
2001.00996v2,2020-01-03T21:51:43Z,2020-01-19 13:25:58,Monitoring the Multivariate Coefficient of Variation using Run Rules Type Control Charts,"In practice, there are processes where the in-control mean and standard deviation of a quality characteristic is not stable. In such cases, the coefficient of variation (CV) is a more appropriate measure for assessing process stability. In this paper, we consider the statistical design of Run Rules based control charts for monitoring the CV of multivariate data. A Markov chain approach is used to evaluate the statistical performance of the proposed charts. The computational results show that the Run Rules based charts outperform significantly the standard Shewhart control chart. Moreover, by choosing an appropriate scheme, the Run Rules based charts perform better than the Rum Sum control chart for monitoring the multivariate CV. An example in a spring manufacturing process is given to illustrate the implementation of the proposed charts.",P. H. Tran|A. C. Rakitzis|H. D. Nguyen|Q. T. Nguyen|K. P. Tran|C. Heuchenne,,https://arxiv.org/abs/2001.00996v2,https://arxiv.org/pdf/2001.00996v2,,"27 pages, 4 figures, 12 tables",,,stat.AP,stat.AP|stat.CO,https://arxiv.org/pdf/2001.00996v2.pdf
1912.09755v1,2019-12-20T11:04:31Z,2019-12-20 11:04:31,A Review of Dispersion Control Charts for Multivariate Individual Observations,"A multivariate control chart is designed to monitor process parameters of multiple correlated quality characteristics. Often data on multivariate processes are collected as individual observations, i.e. as vectors one at the time. Various control charts have been proposed in the literature to monitor the covariance matrix of a process when individual observations are collected. In this study, we review this literature; we find 30 relevant articles from the period 1987-2019. We group the articles into five categories. We observe that less research has been done on CUSUM, high-dimensional and non-parametric type control charts for monitoring the process covariance matrix. We describe each proposed method, state their advantages, and limitations. Finally, we give suggestions for future research.",Jimoh Olawale Ajadi|Zezhong Wang|Inez Maria Zwetsloot,,https://arxiv.org/abs/1912.09755v1,https://arxiv.org/pdf/1912.09755v1,,"43 pages, 2 Figures, 9 Tables",,,stat.ME,stat.ME,https://arxiv.org/pdf/1912.09755v1.pdf
1912.04045v2,2019-12-09T13:58:32Z,2020-07-08 12:15:48,Phase I analysis of hidden operating status for wind turbine,"Data-driven methods based on Supervisory Control and Data Acquisition (SCADA) become a recent trend for wind turbine condition monitoring. However, SCADA data are known to be of low quality due to low sampling frequency and complex turbine working dynamics. In this work, we focus on the phase I analysis of SCADA data to better understand turbines' operating status. As one of the most important characterization, the power curve is used as a benchmark to represent normal performance. A powerful distribution-free control chart is applied after the power generation is adjusted by an accurate power curve model, which explicitly takes into account the known factors that can affect turbines' performance. Informative out-of-control segments have been revealed in real field case studies. This phase I analysis can help improve wind turbine's monitoring, reliability, and maintenance for a smarter wind energy system.",Yuchen Shi|Nan Chen,,https://arxiv.org/abs/1912.04045v2,https://arxiv.org/pdf/1912.04045v2,https://doi.org/10.1109/IEEM44572.2019.8978833,,,10.1109/IEEM44572.2019.8978833,stat.AP,stat.AP,https://arxiv.org/pdf/1912.04045v2.pdf
1911.06242v1,2019-11-13T09:15:32Z,2019-11-13 09:15:32,Condition monitoring and early diagnostics methodologies for hydropower plants,"Hydropower plants are one of the most convenient option for power generation, as they generate energy exploiting a renewable source, they have relatively low operating and maintenance costs, and they may be used to provide ancillary services, exploiting the large reservoirs of available water. The recent advances in Information and Communication Technologies (ICT) and in machine learning methodologies are seen as fundamental enablers to upgrade and modernize the current operation of most hydropower plants, in terms of condition monitoring, early diagnostics and eventually predictive maintenance. While very few works, or running technologies, have been documented so far for the hydro case, in this paper we propose a novel Key Performance Indicator (KPI) that we have recently developed and tested on operating hydropower plants. In particular, we show that after more than one year of operation it has been able to identify several faults, and to support the operation and maintenance tasks of plant operators. Also, we show that the proposed KPI outperforms conventional multivariable process control charts, like the Hotelling $t_2$ index.",Alessandro Betti|Emanuele Crisostomi|Gianluca Paolinelli|Antonio Piazzi|Fabrizio Ruffini|Mauro Tucci,"i-EM S.r.l|Department of Energy, Systems, Territory and Constructions Engineering, University of Pisa and|Pure Power Control S.r.l|i-EM S.r.l|i-EM S.r.l|Department of Energy, Systems, Territory and Constructions Engineering, University of Pisa and",https://arxiv.org/abs/1911.06242v1,https://arxiv.org/pdf/1911.06242v1,,"8 pages, 4 figures. This work has been submitted to the Elsevier Renewable Energy for possible publication",,,eess.SP,eess.SP|cs.LG|stat.ML,https://arxiv.org/pdf/1911.06242v1.pdf
1911.01733v2,2019-11-05T11:50:55Z,2020-05-22 07:38:04,A Control Chart Approach to Power System Line Outage Detection Under Transient Dynamics,"Online transmission line outage detection over the entire network enables timely corrective action to be taken, which prevents a local event from cascading into a large scale blackout. Line outage detection aims to detect an outage as soon as possible after it happened. Traditional methods either do not consider the transient dynamics following an outage or require a full Phasor Measurement Unit (PMU) deployment. Using voltage phase angle data collected from a limited number of PMUs, we propose a real-time dynamic outage detection scheme based on alternating current (AC) power flow model and statistical change detection theory. The proposed method can capture system dynamics since it retains the time-variant and nonlinear nature of the power system. The method is computationally efficient and scales to large and realistic networks. Extensive simulation studies on IEEE 39-bus and 2383-bus systems demonstrated the effectiveness of the proposed method.",Xiaozhou Yang|Nan Chen|Chao Zhai,,https://arxiv.org/abs/1911.01733v2,https://arxiv.org/pdf/1911.01733v2,https://doi.org/10.1109/TPWRS.2020.3006465,"9 pages, 8 figures, under review for IEEE Transactions on Power Systems",,10.1109/TPWRS.2020.3006465,eess.SY,eess.SY|stat.AP,https://arxiv.org/pdf/1911.01733v2.pdf
1907.05453v2,2019-07-11T19:12:24Z,2019-11-07 13:52:06,Model based Level Shift Detection in Autocorrelated Data Streams using a moving window,"Standard Control Chart techniques to detect level shift in data streams assume independence between observations. As data today is collected with high frequency, this assumption is seldom valid. To overcome this, we propose to adapt the off-line test procedure for detection of outliers based on one-step prediction errors proposed by Tsay (1988) into an on-line framework by considering a moving window. Further, we present two algorithms, that in combination, estimate an appropriate test value for our control chart. We test our method on AR(1) processes exposed to level shifts of different sizes and compare it to CUSUM applied to one-step prediction errors. We find that, even though both methods perform comparable when tuned correctly, our method has higher probability of identifying the correct change point of the process. Furthermore, for more complicated processes our method is easier to tune, as the range of window size to be tested is independent of the process.",Jacob Søgaard Larsen|Anders Stockmarr|Bjarne Kjær Ersbøll|Murat Kulahci,,https://arxiv.org/abs/1907.05453v2,https://arxiv.org/pdf/1907.05453v2,,"14 pages, 8 figures and 1 table",,,stat.ME,stat.ME|stat.OT,https://arxiv.org/pdf/1907.05453v2.pdf
1907.00111v3,2019-06-28T22:53:28Z,2020-07-10 05:11:01,An Intrinsic Geometrical Approach for Statistical Process Control of Surface and Manifold Data,"We present a new method for statistical process control (SPC) of a discrete part manufacturing system based on intrinsic geometrical properties of the parts, estimated from three-dimensional sensor data. An intrinsic method has the computational advantage of avoiding the difficult part registration problem, necessary in previous SPC approaches of three-dimensional geometrical data, but inadequate if noncontact sensors are used. The approach estimates the spectrum of the Laplace-Beltrami (LB) operator of the scanned parts and uses a multivariate nonparametric control chart for online process control. Our proposal brings SPC closer to computer vision and computer graphics methods aimed to detect large differences in shape (but not in size). However, the SPC problem differs in that small changes in either shape or size of the parts need to be detected, keeping a controllable false alarm rate and without completely filtering noise. An online or ""Phase II"" method and a scheme for starting up in the absence of prior data (""Phase I"") are presented. Comparison with earlier approaches that require registration shows the LB spectrum method to be more sensitive to rapidly detect small changes in shape and size, including the practical case when the sequence of part datasets is in the form of large, unequal size meshes. A post-alarm diagnostic method to investigate the location of defects on the surface of a part is also presented. While we focus in this article on surface (triangulation) data, the methods can also be applied to point cloud and voxel metrology data.",Xueqi Zhao|Enrique del Castillo,,https://arxiv.org/abs/1907.00111v3,https://arxiv.org/pdf/1907.00111v3,https://doi.org/10.1080/00401706.2020.1772114,,,10.1080/00401706.2020.1772114,stat.AP,stat.AP,https://arxiv.org/pdf/1907.00111v3.pdf
1906.08038v1,2019-06-19T12:14:33Z,2019-06-19 12:14:33,Should Observations be Grouped for Effective Monitoring of Multivariate Process Variability?,"A multivariate dispersion control chart monitors changes in the process variability of multiple correlated quality characteristics. In this article, we investigate and compare the performance of charts designed to monitor variability based on individual and grouped multivariate observations. We compare one of the most well-known methods for monitoring individual observations -- a multivariate EWMA chart proposed by Huwang et al -- to various charts based on grouped observations. In addition, we compare charts based on monitoring with overlapping and nonoverlapping subgroups. We recommend using charts based on overlapping subgroups when monitoring with subgroup data. The effect of subgroup size is also investigated. Steady-state average time to signal is used as performance measure. We show that monitoring methods based on individual observations are the quickest in detecting sustained shifts in the process variability. We use a simulation study to obtain our results and illustrated these with a case study.",Jimoh Olawale Ajadi|Inez Maria Zwetsloot,,https://arxiv.org/abs/1906.08038v1,https://arxiv.org/pdf/1906.08038v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/1906.08038v1.pdf
1903.06675v1,2019-02-14T13:01:06Z,2019-02-14 13:01:06,Markov Chain-based Cost-Optimal Control Charts for Healthcare Data,"Control charts have traditionally been used in industrial statistics, but are constantly seeing new areas of application, especially in the age of Industry 4.0. This paper introduces a new method, which is suitable for applications in the healthcare sector, especially for monitoring a health-characteristic of a patient. We adapt a Markov chain-based approach and develop a method in which not only the shift size (i.e. the degradation of the patient's health) can be random, but the effect of the repair (i.e. treatment) and time between samplings (i.e. visits) too. This means that we do not use many often-present assumptions which are usually not applicable for medical treatments. The average cost of the protocol, which is determined by the time between samplings and the control limit, can be estimated using the stationary distribution of the Markov chain.
  Furthermore, we incorporate the standard deviation of the cost into the optimisation procedure, which is often very important from a process control viewpoint. The sensitivity of the optimal parameters and the resulting average cost and cost standard deviation on different parameter values is investigated. We demonstrate the usefulness of the approach for real-life data of patients treated in Hungary: namely the monitoring of cholesterol level of patients with cardiovascular event risk. The results showed that the optimal parameters from our approach can be somewhat different from the original medical parameters.",Balázs Dobi|András Zempléni,,https://arxiv.org/abs/1903.06675v1,https://arxiv.org/pdf/1903.06675v1,,,,,stat.AP,stat.AP|cs.CY|stat.ME|stat.ML,https://arxiv.org/pdf/1903.06675v1.pdf
1902.02270v1,2019-02-06T16:53:17Z,2019-02-06 16:53:17,Using statistical control charts to monitor duration-based performance of project,"Monitoring of project performance is a crucial task of project managers that significantly affect the project success or failure. Earned Value Management (EVM) is a well-known tool to evaluate project performance and effective technique for identifying delays and proposing appropriate corrective actions. The original EVM analysis is a monetary-based method and it can be misleading in the evaluation of the project schedule performance and estimation of the project duration. Earned Duration Management (EDM) is a more recent method which introduces metrics for the project schedule performance evaluation and improves EVM analysis. In this paper, we apply statistical control charts on EDM indices to better investigate the variations of project schedule performance. Control charts are decision support tools to detect the out of control performance. Usually project performance measurements are auto-correlated and not following the normal distribution. Hence, in this paper, a two-step adjustment framework is proposed to make the control charts applicable to non-normal and auto-correlated measurements. The case study project illustrates how the new method can be implemented in practice. The numerical results conclude that that employing control chart method along with analyzing the actual values of EDM indices increase the capability of project management teams to detect cost and schedule problems on time",Nooshin Yousefi|Ahmad Sobhani|Leila Moslemi Naeni|Kenneth R. Currie,,https://arxiv.org/abs/1902.02270v1,https://arxiv.org/pdf/1902.02270v1,https://doi.org/10.19255/jmpm415,,,10.19255/jmpm415,stat.AP,stat.AP,https://arxiv.org/pdf/1902.02270v1.pdf
1901.03701v1,2019-01-11T10:50:51Z,2019-01-11 10:50:51,Robust Adaptive Control Charts,"In statistical process control, procedures are applied that require relatively strict conditions for their use. If such assumptions are violated, these methods become inefficient, leading to increased incidence of false signals. Therefore, a robust version of control charts is sought to be less sensitive with respect to a breach of normality and independence in measurements. Robust control charts, however, usually increase the delay in the detection of assignable causes. This negative effect can, to some extent, be removed with the aid of an adaptive approach.",Gejza Dohnal,,https://arxiv.org/abs/1901.03701v1,https://arxiv.org/pdf/1901.03701v1,,"8 pages, 3 figures. The paper was presented as a contribution on Quality and Productivity Research Conference, Long Beach, CA, June 4 - 7 2012",,,stat.OT,stat.OT,https://arxiv.org/pdf/1901.03701v1.pdf
1812.11132v1,2018-12-24T21:01:36Z,2018-12-24 21:01:36,Application of Robust Estimators in Shewhart S-Charts,"Maintaining the quality of manufactured products at a desired level is known to increase customer satisfaction and profitability. Shewhart control chart is the most widely used in statistical process control (SPC) technique to monitor the quality of products and control process variability. Based on the assumption of independent and normally distributed data sets, sample mean and standard deviation statistics are known to be the most efficient conventional estimators to determine the process location and scale, respectively. On the other hand, there is not guarantee that the real-world process data would be normally distributed: outliers may exist, and/or sampled population may be contaminated. In such cases, efficiency of the conventional estimators is significantly reduced, and power of the Shewhart charts may be undesirably low, e.g. occasional outliers in the rational subgroups (Phase I dataset) may drastically affect the sample mean and standard deviation, resulting a serious delay in detection of inferior products (Phase II procedure). For more efficient analyses, it is required to use robust estimators against contaminations. Consequently, it is determined that robust estimators are more efficient both against diffuse localized and symmetric-asymmetric contaminations, and have higher power in detecting disturbances, compared to conventional methods.",Burak Alakent|Ece C. Mutlu,,https://arxiv.org/abs/1812.11132v1,https://arxiv.org/pdf/1812.11132v1,,,,,stat.OT,stat.OT,https://arxiv.org/pdf/1812.11132v1.pdf
1809.03127v2,2018-09-10T04:28:42Z,2019-06-11 08:14:43,Monitoring data quality for telehealth systems in the presence of missing data,"Background: All-in-one station-based health monitoring devices are implemented in elder homes in Hong Kong to support the monitoring of vital signs of the elderly. During a pilot study, it was discovered that the systolic blood pressure was incorrectly measured during multiple weeks. A real-time solution was needed to identify future data quality issues as soon as possible.
  Methods: Control charts are an effective tool for real-time monitoring and signaling issues (changes) in data. In this study, as in other healthcare applications, many observations are missing. Few methods are available for monitoring data with missing observations. A data quality monitoring method is developed to signal issues with the accuracy of the collected data quickly. This method has the ability to deal with missing observations. A Hotelling's T-squared control chart is selected as the basis for our proposed method.
  Findings: The proposed method is retrospectively validated on a case study with a known measurement error in the systolic blood pressure measurements. The method is able to adequately detect this data quality problem. The proposed method was integrated into a personalized telehealth monitoring system and prospectively implemented in a second case study. It was found that the proposed scheme supports the control of data quality.
  Conclusions: Data quality is an important issue and control charts are useful for real-time monitoring of data quality. However, these charts must be adjusted to account for missing data that often occur in healthcare context.",Tahir Mahmood|Philipp Wittenberg|Inez Maria Zwetsloot|Hailiang Wang|Kwok Leung Tsui,,https://arxiv.org/abs/1809.03127v2,https://arxiv.org/pdf/1809.03127v2,https://doi.org/10.1016/j.ijmedinf.2019.03.011,"13 pages, 5 figures",Int. J. Med. Inform. 126 (2019) 156-163,10.1016/j.ijmedinf.2019.03.011,stat.AP,stat.AP|stat.ME,https://arxiv.org/pdf/1809.03127v2.pdf
1808.05069v1,2018-08-15T13:30:54Z,2018-08-15 13:30:54,The Steady-State Behavior of Multivariate Exponentially Weighted Moving Average Control Charts,"Multivariate Exponentially Weighted Moving Average, MEWMA, charts are popular, handy and effective procedures to detect distributional changes in a stream of multivariate data. For doing appropriate performance analysis, dealing with the steady-state behavior of the MEWMA statistic is essential. Going beyond early papers, we derive quite accurate approximations of the respective steady-state densities of the MEWMA statistic. It turns out that these densities could be rewritten as the product of two functions depending on one argument only which allows feasible calculation. For proving the related statements, the presentation of the non-central chisquare density deploying the confluent hypergeometric limit function is applied. Using the new methods it was found that for large dimensions, the steady-state behavior becomes different to what one might expect from the univariate monitoring field. Based on the integral equation driven methods, steady-state and worst-case average run lengths are calculated with higher accuracy than before. Eventually, optimal MEWMA smoothing constants are derived for all considered measures.",Sven Knoth,,https://arxiv.org/abs/1808.05069v1,https://arxiv.org/pdf/1808.05069v1,https://doi.org/10.1080/07474946.2018.1554890,,,10.1080/07474946.2018.1554890,stat.ME,stat.ME,https://arxiv.org/pdf/1808.05069v1.pdf
1804.01454v1,2018-04-04T15:05:36Z,2018-04-04 15:05:36,Beta regression control chart for monitoring fractions and proportions,"Regression control charts are usually used to monitor variables of interest that are related to control variables. However, for fraction and/or proportion data, the use of standard regression control charts may not be adequate, since the linear regression model assumes the normality of the interest variable. To work around this problem, we propose the beta regression control chart (BRCC). The BRCC is useful for monitoring fraction, rate and/or proportion data sets when they are related to control variables. The proposed control chart assumes that the mean and dispersion parameters of beta distributed variables are related to the exogenous variables, being modeled using regression structures. The BRCC is numerically assessed through an extensive Monte Carlo simulation study, showing good performance in terms of average run length (ARL). Two applications to real data are presented, evidencing the practical applicability of the proposed method.",Fábio Mariano Bayer|Catia Michele Tondolo|Fernanda Maria Müller,,https://arxiv.org/abs/1804.01454v1,https://arxiv.org/pdf/1804.01454v1,,Accepted paper,"Computers \& Industrial Engineering, 2018",,stat.ME,stat.ME,https://arxiv.org/pdf/1804.01454v1.pdf
1804.00760v2,2018-04-02T23:28:08Z,2019-05-05 20:01:05,Process Control with Highly Left Censored Data,"The need to monitor industrial processes, detecting changes in process parameters in order to promptly correct problems that may arise, generates a particular area of interest. This is particularly critical and complex when the measured value falls below the sensitivity limits of the measuring system or below detection limits, causing much of their observations are incomplete. Such observations to be called incomplete observations or left censored data. With a high level of censorship, for example greater than 70%, the application of traditional methods for monitoring processes is not appropriate. It is required to use appropriate data analysis statistical techniques, to assess the actual state of the process at any time. This paper proposes a way to estimate process parameters in such cases and presents the corresponding control chart, from an algorithm that is also presented.",Javier Neira Rueda|Andres Carrion Garcia,,https://arxiv.org/abs/1804.00760v2,https://arxiv.org/pdf/1804.00760v2,,14 pages,,,stat.AP,stat.AP,https://arxiv.org/pdf/1804.00760v2.pdf
1804.00482v1,2018-04-02T13:31:11Z,2018-04-02 13:31:11,Real Time Sentiment Change Detection of Twitter Data Streams,"In the past few years, there has been a huge growth in Twitter sentiment analysis having already provided a fair amount of research on sentiment detection of public opinion among Twitter users. Given the fact that Twitter messages are generated constantly with dizzying rates, a huge volume of streaming data is created, thus there is an imperative need for accurate methods for knowledge discovery and mining of this information. Although there exists a plethora of twitter sentiment analysis methods in the recent literature, the researchers have shifted to real-time sentiment identification on twitter streaming data, as expected. A major challenge is to deal with the Big Data challenges arising in Twitter streaming applications concerning both Volume and Velocity. Under this perspective, in this paper, a methodological approach based on open source tools is provided for real-time detection of changes in sentiment that is ultra efficient with respect to both memory consumption and computational cost. This is achieved by iteratively collecting tweets in real time and discarding them immediately after their process. For this purpose, we employ the Lexicon approach for sentiment characterizations, while change detection is achieved through appropriate control charts that do not require historical information. We believe that the proposed methodology provides the trigger for a potential large-scale monitoring of threads in an attempt to discover fake news spread or propaganda efforts in their early stages. Our experimental real-time analysis based on a recent hashtag provides evidence that the proposed approach can detect meaningful sentiment changes across a hashtags lifetime.",Sotiris K. Tasoulis|Aristidis G. Vrahatis|Spiros V. Georgakopoulos|Vassilis P. Plagianakos,,https://arxiv.org/abs/1804.00482v1,https://arxiv.org/pdf/1804.00482v1,https://doi.org/10.1109/INISTA.2018.8466326,,,10.1109/INISTA.2018.8466326,cs.CL,cs.CL,https://arxiv.org/pdf/1804.00482v1.pdf
1801.06532v2,2018-01-19T18:52:52Z,2025-11-17 19:25:28,Distribution-Free Control Charts Based on Runs and Patterns,"We propose distribution-free runs-based control charts for detecting location shifts. Using the fact that given the number of total successes, the outcomes of a sequence of Bernoulli trials are random permutations, we are able to control the conditional probability of a signal detected at current time given that there is not alarm before at a pre-determined level. This leads to a desired in-control average run length and data-dependent control limits. Two common runs statistics, the longest run statistic and the scan statitsic, are studied in detail and their exact conditional distributions given the number of total successes are obtained using the finite Markov chain imbedding technique. Numerical results are given to evaluate the performance of the proposed control charts.",Tung-Lung Wu,,https://arxiv.org/abs/1801.06532v2,https://arxiv.org/pdf/1801.06532v2,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/1801.06532v2.pdf
1801.01660v1,2018-01-05T08:04:48Z,2018-01-05 08:04:48,Control charts in a multi product environment: An application study,"In this article an SPC case study is presented. It consists of monitoring a manufacturing process used for different products of similar kind. So far, each of these products is monitored individually. However, if there is e.g. a quality problem with one joint component, this signal will be distributed over different control charts. Therefor a standardization is introduced, similar to short run SPC methods. Then control chart methods are applied to detect process deviations. If there are observations out of control, a next step is taken and process information are analysed in order to derive possible root causes.",Thomas Muehlenstaedt,,https://arxiv.org/abs/1801.01660v1,https://arxiv.org/pdf/1801.01660v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/1801.01660v1.pdf
1712.05072v1,2017-12-14T02:11:14Z,2017-12-14 02:11:14,Nonparametric Adaptive CUSUM Chart for Detecting Arbitrary Distributional Changes,"Nonparametric control charts that can detect arbitrary distributional changes are highly desirable due to their flexibility to adapt to different distributional assumptions and distributional changes. However, most of such control charts in the literature either involve some tuning parameter, which needs to be pre-specified, or involve intensive computation. In this paper, we propose a new nonparametric adaptive CUSUM chart for detecting arbitrary distributional changes. The proposed control chart does not depend on any tuning parameter and is efficient in computation. Its self-starting nature makes the proposed control chart applicable to situations where no sufficiently large reference data are available. Our proposed control chart also has a built-in post-signal diagnostics function that can identify what kind of distributional changes have occurred after an alarm. Our simulation study and real data analysis show that the proposed control chart performs well across a broad range of settings, and compares favorably with existing nonparametric control charts.",Jun Li,,https://arxiv.org/abs/1712.05072v1,https://arxiv.org/pdf/1712.05072v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/1712.05072v1.pdf
1712.02860v2,2017-12-07T21:10:27Z,2017-12-18 13:22:34,Remarks on Bayesian Control Charts,"There is a considerable amount of ongoing research on the use of Bayesian control charts for detecting a shift from a good quality distribution to a bad quality distribution in univariate and multivariate processes. It is widely claimed that Bayesian control charts are economically optimal; see, for example, Calabrese (1995) [Bayesian process control for attributes. Management Science, DOI: 10.1287/mnsc.41.4.637] and Makis (2008) [Multivariate Bayesian control chart. Operations Research, DOI: 10.1287/opre.1070.0495]. Some researchers also generalize the optimality of controls defined based on posterior probabilities to the class of partially observable Markov decision processes. This note points out that the existing Bayesian control charts cannot generally be optimal because many years ago an analytical counterexample was provided by Taylor (1965) [Markovian sequential replacement processes. The Annals of Mathematical Statistics, DOI: 10.1214/aoms/1177699796].",Amir Ahmadi-Javid|Mohsen Ebadi,,https://arxiv.org/abs/1712.02860v2,https://arxiv.org/pdf/1712.02860v2,,,,,stat.AP,stat.AP|cs.CE|econ.GN|math.OC|math.PR,https://arxiv.org/pdf/1712.02860v2.pdf
1711.04441v1,2017-11-13T06:58:07Z,2017-11-13 06:58:07,Change Detection in a Dynamic Stream of Attributed Networks,"While anomaly detection in static networks has been extensively studied, only recently, researchers have focused on dynamic networks. This trend is mainly due to the capacity of dynamic networks in representing complex physical, biological, cyber, and social systems. This paper proposes a new methodology for modeling and monitoring of dynamic attributed networks for quick detection of temporal changes in network structures. In this methodology, the generalized linear model (GLM) is used to model static attributed networks. This model is then combined with a state transition equation to capture the dynamic behavior of the system. Extended Kalman filter (EKF) is used as an online, recursive inference procedure to predict and update network parameters over time. In order to detect changes in the underlying mechanism of edge formation, prediction residuals are monitored through an Exponentially Weighted Moving Average (EWMA) control chart. The proposed modeling and monitoring procedure is examined through simulations for attributed binary and weighted networks. The email communication data from the Enron corporation is used as a case study to show how the method can be applied in real-world problems.",Mostafa Reisi Gahrooei|Kamran Paynabar,,https://arxiv.org/abs/1711.04441v1,https://arxiv.org/pdf/1711.04441v1,,,,,stat.ME,stat.ME,https://arxiv.org/pdf/1711.04441v1.pdf
1709.04979v1,2017-09-14T21:11:53Z,2017-09-14 21:11:53,An improved quality control chart to monitor the mean based on ranked sets,"In this study, we considered the design and performance of control charts using neoteric ranked set sampling (NRSS) in monitoring normal distributed processes. NRSS is a recently proposed sampling design, based on the traditional ranked set sampling (RSS). We evaluated NRSS control charts by average run length (ARL), based on Monte Carlo simulation results. NRSS control charts performed the best, compared to RSS and some of its extensions, in most simulated scenarios. The impact of imperfect ranking was also evaluated. An application on strength concrete data serves as an illustration of the proposed method.",G. P. Silva|C. A. Taconeli|W. M. Zeviani|I. S. Guimaraes,,https://arxiv.org/abs/1709.04979v1,https://arxiv.org/pdf/1709.04979v1,,"27 pages, 9 figures, to be submitted",,,stat.ME,stat.ME,https://arxiv.org/pdf/1709.04979v1.pdf
1708.06160v1,2017-08-21T11:38:26Z,2017-08-21 11:38:26,Economic Design of Memory-Type Control Charts: The Fallacy of the Formula Proposed by Lorenzen and Vance (1986),"The memory-type control charts, such as EWMA and CUSUM, are powerful tools for detecting small quality changes in univariate and multivariate processes. Many papers on economic design of these control charts use the formula proposed by Lorenzen and Vance (1986) [Lorenzen, T. J., & Vance, L. C. (1986). The economic design of control charts: A unified approach. Technometrics, 28(1), 3-10, DOI: 10.2307/1269598]. This paper shows that this formula is not correct for memory-type control charts and its values can significantly deviate from the original values even if the ARL values used in this formula are accurately computed. Consequently, the use of this formula can result in charts that are not economically optimal. The formula is corrected for memory-type control charts, but unfortunately the modified formula is not a helpful tool from a computational perspective. We show that simulation-based optimization is a possible alternative method.",Amir Ahmadi-Javid|Mohsen Ebadi,,https://arxiv.org/abs/1708.06160v1,https://arxiv.org/pdf/1708.06160v1,https://doi.org/10.1007/s00180-020-01019-6,"Computational Statistics, 2020","Ahmadi-Javid, A., & Ebadi, M. (2020). Economic design of memory-type control charts: The fallacy of the formula proposed by Lorenzen and Vance (1986). Computational Statistics, DOI: 10.1007/s00180-020-01019-6",10.1007/s00180-020-01019-6,stat.AP,stat.AP|cs.CE|econ.GN|math.OC,https://arxiv.org/pdf/1708.06160v1.pdf
1607.07423v3,2016-07-25T19:40:55Z,2016-07-29 20:31:54,A Non-Parametric Control Chart For High Frequency Multivariate Data,"Support Vector Data Description (SVDD) is a machine learning technique used for single class classification and outlier detection. SVDD based K-chart was first introduced by Sun and Tsung for monitoring multivariate processes when underlying distribution of process parameters or quality characteristics depart from Normality. The method first trains a SVDD model on data obtained from stable or in-control operations of the process to obtain a threshold $R^2$ and kernel center a. For each new observation, its Kernel distance from the Kernel center a is calculated. The kernel distance is compared against the threshold $R^2$ to determine if the observation is within the control limits. The non-parametric K-chart provides an attractive alternative to the traditional control charts such as the Hotelling's $T^2$ charts when distribution of the underlying multivariate data is either non-normal or is unknown. But there are challenges when K-chart is deployed in practice. The K-chart requires calculating kernel distance of each new observation but there are no guidelines on how to interpret the kernel distance plot and infer about shifts in process mean or changes in process variation. This limits the application of K-charts in big-data applications such as equipment health monitoring, where observations are generated at a very high frequency. In this scenario, the analyst using the K-chart is inundated with kernel distance results at a very high frequency, generally without any recourse for detecting presence of any assignable causes of variation. We propose a new SVDD based control chart, called as $K_T$ chart, which addresses challenges encountered when using K-chart for big-data applications. The $K_T$ charts can be used to simultaneously track process variation and central tendency. We illustrate the successful use of $K_T$ chart using the Tennessee Eastman process data.",Deovrat Kakde|Sergriy Peredriy|Arin Chaudhuri|Anya Mcguirk,,https://arxiv.org/abs/1607.07423v3,https://arxiv.org/pdf/1607.07423v3,https://doi.org/10.1109/RAM.2017.7889786,,,10.1109/RAM.2017.7889786,cs.LG,cs.LG|stat.AP|stat.ME|stat.ML,https://arxiv.org/pdf/1607.07423v3.pdf
1511.08355v1,2015-11-26T11:03:21Z,2015-11-26 11:03:21,From Static to Dynamic Tag Population Estimation: An Extended Kalman Filter Perspective,"Tag population estimation has recently attracted significant research attention due to its paramount importance on a variety of radio frequency identification (RFID) applications. However, most, if not all, of existing estimation mechanisms are proposed for the static case where tag population remains constant during the estimation process, thus leaving the more challenging dynamic case unaddressed, despite the fundamental importance of the latter case on both theoretical analysis and practical application. In order to bridge this gap, %based on \textit{dynamic framed-slotted ALOHA} (DFSA) protocol, we devote this paper to designing a generic framework of stable and accurate tag population estimation schemes based on Kalman filter for both static and dynamic RFID systems. %The objective is to devise estimation schemes and analyze the boundedness of estimation error. Technically, we first model the dynamics of RFID systems as discrete stochastic processes and leverage the techniques in extended Kalman filter (EKF) and cumulative sum control chart (CUSUM) to estimate tag population for both static and dynamic systems. By employing Lyapunov drift analysis, we mathematically characterise the performance of the proposed framework in terms of estimation accuracy and convergence speed by deriving the closed-form conditions on the design parameters under which our scheme can stabilise around the real population size with bounded relative estimation error that tends to zero with exponential convergence rate.",Jihong Yu|Lin Chen,,https://arxiv.org/abs/1511.08355v1,https://arxiv.org/pdf/1511.08355v1,,,,,eess.SY,eess.SY,https://arxiv.org/pdf/1511.08355v1.pdf
1510.08694v1,2015-10-29T13:58:17Z,2015-10-29 13:58:17,Bridging centrality and extremity: Refining empirical data depth using extreme value statistics,"Statistical depth measures the centrality of a point with respect to a given distribution or data cloud. It provides a natural center-outward ordering of multivariate data points and yields a systematic nonparametric multivariate analysis scheme. In particular, the half-space depth is shown to have many desirable properties and broad applicability. However, the empirical half-space depth is zero outside the convex hull of the data. This property has rendered the empirical half-space depth useless outside the data cloud, and limited its utility in applications where the extreme outlying probability mass is the focal point, such as in classification problems and control charts with very small false alarm rates. To address this issue, we apply extreme value statistics to refine the empirical half-space depth in ""the tail."" This provides an important linkage between data depth, which is useful for inference on centrality, and extreme value statistics, which is useful for inference on extremity. The refined empirical half-space depth can thus extend all its utilities beyond the data cloud, and hence broaden greatly its applicability. The refined estimator is shown to have substantially improved upon the empirical estimator in theory and simulations. The benefit of this improvement is also demonstrated through the applications in classification and statistical process control.",John H. J. Einmahl|Jun Li|Regina Y. Liu,,https://arxiv.org/abs/1510.08694v1,https://arxiv.org/pdf/1510.08694v1,https://doi.org/10.1214/15-AOS1359,Published at http://dx.doi.org/10.1214/15-AOS1359 in the Annals of Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics (http://www.imstat.org),"Annals of Statistics 2015, Vol. 43, No. 6, 2738-2765",10.1214/15-AOS1359,math.ST,math.ST,https://arxiv.org/pdf/1510.08694v1.pdf
1507.01044v1,2015-07-03T22:28:36Z,2015-07-03 22:28:36,A first look at the performances of a Bayesian chart to monitor the ratio of two Weibull percentiles,"The aim of the present work is to investigate the performances of a specific Bayesian control chart used to compare two processes. The chart monitors the ratio of the percentiles of a key characteristic associated with the processes. The variability of such a characteristic is modeled via the Weibull distribution and a practical Bayesian approach to deal with Weibull data is adopted. The percentiles of the two monitored processes are assumed to be independent random variables. The Weibull distributions of the key characteristic of both processes are assumed to have the same and stable shape parameter. This is usually experienced in practice because the Weibull shape parameter is related to the main involved factor of variability. However, if a change of the shape parameters of the processes is suspected, the involved distributions can be used to monitor their stability. We first tested the effects of the number of the training data on the responsiveness of the chart. Then we tested the robustness of the chart in spite of very poor prior information. To this end, the prior values were changed to reflect a 50% shift in both directions from the original values of the shape parameter and the percentiles of the two monitored processes. Finally, various combinations of shifts were considered for the sampling distributions after the Phase I, with the purpose of estimating the diagnostic ability of the charts to signal an out-of-control state. The traditional approach based on the Average Run Length, empirically computed via a Monte Carlo simulation, was adopted.",Pasquale Erto,,https://arxiv.org/abs/1507.01044v1,https://arxiv.org/pdf/1507.01044v1,,"9 pages, 3 figures, 3 tables. Invited talk at the 4th International Symposium on Statistical Process Monitoring (http://isspm2015.stat.unipd.it), July 7-9, 2015, Padua, Italy",,,stat.CO,stat.CO,https://arxiv.org/pdf/1507.01044v1.pdf
1506.02433v1,2015-06-08T10:46:13Z,2015-06-08 10:46:13,Steady State of Pedestrian Flow in Bottleneck Experiments,"Experiments with pedestrians could depend strongly on initial conditions. Comparisons of the results of such experiments require to distinguish carefully between transient state and steady state. In this work, a feasible algorithm - Cumulative Sum Control Chart - is proposed and improved to automatically detect steady states from density and speed time series of bottleneck experiments. The threshold of the detection parameter in the algorithm is calibrated using an autoregressive model. Comparing the detected steady states with previous manually selected ones, the modified algorithm gives more reproducible results. For the applications, three groups of bottleneck experiments are analysed and the steady states are detected. The study about pedestrian flow shows that the difference between the flows in all states and in steady state mainly depends on the ratio of pedestrian number to bottleneck width. When the ratio is higher than a critical value (approximately 115 persons/m), the flow in all states is almost identical with the flow in steady state. Thus we have more possibilities to compare the flows from different experiments, especially when the detection of steady states is difficult.",Weichen Liao|Antoine Tordeux|Armin Seyfried|Mohcine Chraibi|Kevin Drzycimski|Xiaoping Zheng|Ying Zhao,,https://arxiv.org/abs/1506.02433v1,https://arxiv.org/pdf/1506.02433v1,https://doi.org/10.1016/j.physa.2016.05.051,"19 pages, 7 figures",,10.1016/j.physa.2016.05.051,physics.soc-ph,physics.soc-ph,https://arxiv.org/pdf/1506.02433v1.pdf
1411.2081v1,2014-11-08T05:11:01Z,2014-11-08 05:11:01,Educational data mining using jmp,"Educational Data Mining is a growing trend in case of higher education. The quality of the Educational Institute may be enhanced through discovering hidden knowledge from the student databases/ data warehouses. Present paper is designed to carry out a comparative study with the TDC (Three Year Degree) Course students of different colleges affiliated to Dibrugarh University. The study is conducted with major subject wise, gender wise and category/caste wise. The experimental results may be visualized with Scatterplot3D, Bubble Plot, Fit Y by X, Run Chart, Control Chart etc. of the SAS JMP Software.",Sadiq Hussain|G. C. Hazarika,,https://arxiv.org/abs/1411.2081v1,https://arxiv.org/pdf/1411.2081v1,,,,,cs.CY,cs.CY,https://arxiv.org/pdf/1411.2081v1.pdf
1403.0668v1,2014-03-04T02:54:30Z,2014-03-04 02:54:30,Estimating Multiple Step Shifts in a Gaussian Process Mean with an Application to Phase I Control Chart Analysis,"In preliminary analysis of control charts, one may encounter multiple shifts and/or outliers especially with a large number of observations. The following paper addresses this problem. A statistical model for detecting and estimating multiple change points in a finite batch of retrospective (phase I)data is proposed based on likelihood ratio test. We consider a univariate normal distribution with multiple step shifts occurred in predefined locations of process mean. A numerical example is performed to illustrate the efficiency of our method. Finally, performance comparisons, based on accuracy measures and precision measures, are explored through simulation studies.",Issac Shams|Saeede Ajorlou|Kai Yang,,https://arxiv.org/abs/1403.0668v1,https://arxiv.org/pdf/1403.0668v1,,"5 pages, to be submitted in IEEE CASE 2014",,,stat.AP,stat.AP,https://arxiv.org/pdf/1403.0668v1.pdf
1308.0691v1,2013-08-03T12:39:00Z,2013-08-03 12:39:00,A semi-empirical Bayesian chart to monitor Weibull percentiles,"This paper develops a Bayesian control chart for the percentiles of the Weibull distribution, when both its in-control and out-of-control parameters are unknown. The Bayesian approach enhances parameter estimates for small sample sizes that occur when monitoring rare events as in high-reliability applications or genetic mutations. The chart monitors the parameters of the Weibull distribution directly, instead of transforming the data as most Weibull-based charts do in order to comply with their normality assumption. The chart uses the whole accumulated knowledge resulting from the likelihood of the current sample combined with the information given by both the initial prior knowledge and all the past samples. The chart is adapting since its control limits change (e.g. narrow) during the Phase I. An example is presented and good Average Run Length properties are demonstrated. In addition, the paper gives insights into the nature of monitoring Weibull processes by highlighting the relationship between distribution and process parameters.",Pasquale Erto|Giuliana Pallotta|Christina M. Mastrangelo,,https://arxiv.org/abs/1308.0691v1,https://arxiv.org/pdf/1308.0691v1,,"21 pages, 3 figures, 5 tables",,,stat.ME,stat.ME,https://arxiv.org/pdf/1308.0691v1.pdf
1305.5962v3,2013-05-25T19:43:56Z,2015-06-30 18:46:47,A note on monitoring ratios of two Weibull percentiles,"This note introduces a new Bayesian control chart to compare two processes by monitoring the ratio of their percentiles under Weibull assumption. Both in-control and out-of-control parameters are supposed unknown. The chart analyses the sampling data directly, instead of transforming them in order to comply with the usual normality assumption, as most charts do. The chart uses the whole accumulated knowledge, resulting from the current and all the past samples, to monitor the current value of the ratio. Two real applications in the wood industry and in the concrete industry give a first picture of the features of the chart.",Pasquale Erto,,https://arxiv.org/abs/1305.5962v3,https://arxiv.org/pdf/1305.5962v3,,13 pages; 4 figures; 3 tables,,,stat.AP,stat.AP,https://arxiv.org/pdf/1305.5962v3.pdf
1305.4318v1,2013-05-19T02:45:20Z,2013-05-19 02:45:20,A nonparametric CUSUM control chart based on the Mann-Whitney statistic,This article aims to consider a new univariate nonparametric cumulative sum (CUSUM) control chart for small shift of location based on both change-point model and Mann-Whitney statistic. Some comparisons on the performances of the proposed chart with other charts as well as the properties of the test statistic are presented. Simulations indicate that the proposed chart is sensitive in detection of the small mean shifts of the process by a high intensive accumulation of sample information when the underlying variable is completely distribution-free.,Dabuxilatu Wang|Qiang Xiong,,https://arxiv.org/abs/1305.4318v1,https://arxiv.org/pdf/1305.4318v1,,"13 pages, 2 table",,,stat.ME,stat.ME,https://arxiv.org/pdf/1305.4318v1.pdf
1211.4262v1,2012-11-18T22:06:48Z,2012-11-18 22:06:48,Univariate and data-depth based multivariate control charts using trimmed mean and winsorized standard deviation,"Over the years, the most popularly used control chart for statistical process control has been Shewhart's $\bar{X}-S$ or $\bar{X}-R$ chart along with its multivariate generalizations. But, such control charts suffer from the lack of robustness. In this paper, we propose a modified and improved version of Shewhart chart, based on trimmed mean and winsorized variance that proves robust and more efficient. We have generalized this approach of ours with suitable modifications using depth functions for Multivariate control charts and EWMA charts as well. We have discussed the theoretical properties of our proposed statistics and have shown the efficiency of our methodology on univariate and multivariate simulated datasets. We have also compared our approach to the other popular alternatives to Shewhart Chart already proposed and established the efficacy of our methodology.",Kushal Kr. Dey|Kumaresh Dhara|Bikram Karmakar|Sukalyan Sengupta,,https://arxiv.org/abs/1211.4262v1,https://arxiv.org/pdf/1211.4262v1,,"This paper consists of 15 pages, 2 figures, and 5 tables. This paper was presented by Kumaresh Dhara at the 29th Quality Productivity and Research Conference (QPRC) 2012 held at California State University, Long Beach, CA",,,stat.CO,stat.CO|stat.ME,https://arxiv.org/pdf/1211.4262v1.pdf
1209.4678v1,2012-09-20T22:34:57Z,2012-09-20 22:34:57,On Control Charts for Monitoring the Variance of a Time Series,"In this paper we derive control charts for the variance of a Gaussian process using the likelihood ratio approach, the generalized likelihood ratio approach, the sequential probability ratio method and a generalized sequential probability ratio procedure, the Shiryaev-Roberts procedure and a generalized Shiryaev-Roberts ap- proach. Recursive presentations for the calculation of the control statistics are given for autoregressive processes of order 1. In an extensive simulation study these schemes are compared with existing control charts for the variance. In order to asses the performance of the schemes both the average run length and the average delay are used.",Taras Lazariv|Wolfgang Schmid|Svitlana Zabolotska,,https://arxiv.org/abs/1209.4678v1,https://arxiv.org/pdf/1209.4678v1,,"30 pages, 4 figures, 4 tables",,,stat.AP,stat.AP|stat.CO|stat.OT,https://arxiv.org/pdf/1209.4678v1.pdf
1205.6440v1,2012-05-29T18:10:25Z,2012-05-29 18:10:25,Monitoring Software Reliability using Statistical Process Control An Ordered Statistics Approach,"The nature and complexity of software have changed significantly in the last few decades. With the easy availability of computing power, deeper and broader applications are made. It has been extremely necessary to produce good quality software with high precession of reliability right in the first place. Olden day's software errors and bugs were fixed at a later stage in the software development. Today to produce high quality reliable software and to keep a specific time schedule is a big challenge. To cope up the challenge many concepts, methodology and practices of software engineering have been evolved for developing reliable software. Better methods of controlling the process of software production are underway. One of such methods to assess the software reliability is using control charts. In this paper we proposed an NHPP based control mechanism by using order statistics with cumulative quantity between observations of failure data using mean value function of exponential distribution.",Bandla Srinivasa Rao|R. Satya Prasad|R. R. L. Kantham,,https://arxiv.org/abs/1205.6440v1,https://arxiv.org/pdf/1205.6440v1,https://doi.org/10.5120/3917-5515,International Journal of Computer Applications; Published by Foundation of Computer Science,"International Journal of Computer Applications 32(7):28-33, October 2011",10.5120/3917-5515,cs.SE,cs.SE,https://arxiv.org/pdf/1205.6440v1.pdf
1203.4661v1,2012-03-21T06:59:11Z,2012-03-21 06:59:11,Profile control charts based on nonparametric $L$-1 regression methods,"Classical statistical process control often relies on univariate characteristics. In many contemporary applications, however, the quality of products must be characterized by some functional relation between a response variable and its explanatory variables. Monitoring such functional profiles has been a rapidly growing field due to increasing demands. This paper develops a novel nonparametric $L$-1 location-scale model to screen the shapes of profiles. The model is built on three basic elements: location shifts, local shape distortions, and overall shape deviations, which are quantified by three individual metrics. The proposed approach is applied to the previously analyzed vertical density profile data, leading to some interesting insights.",Ying Wei|Zhibiao Zhao|Dennis K. J. Lin,,https://arxiv.org/abs/1203.4661v1,https://arxiv.org/pdf/1203.4661v1,https://doi.org/10.1214/11-AOAS501,Published in at http://dx.doi.org/10.1214/11-AOAS501 the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org),"Annals of Applied Statistics 2012, Vol. 6, No. 1, 409-427",10.1214/11-AOAS501,stat.AP,stat.AP,https://arxiv.org/pdf/1203.4661v1.pdf
1203.3882v1,2012-03-17T18:20:01Z,2012-03-17 18:20:01,A Note On the Use of Fiducial Limits for Control Charts,"Many of the early works in the quality control literature construct control limits through the use of graphs and tables as described in Wortham and Ringer (1972). However, the methods used in this literature are restricted to using only the values that the graphs and tables can provide and to the case where the parameters of the underlying distribution are known. In this note, we briefly describe a technique which can be used to calculate exact control limits without the use of graphs or tables. We also describe what are commonly referred to in the literature as fiducial limits. Fiducial limits are often used as the limits in control charting when the parameters of the underlying distribution are unknown.",Mokin Lee|Chanseok Park,,https://arxiv.org/abs/1203.3882v1,https://arxiv.org/pdf/1203.3882v1,,,,,stat.AP,stat.AP,https://arxiv.org/pdf/1203.3882v1.pdf
1111.4180v1,2011-11-17T18:59:04Z,2011-11-17 18:59:04,Guaranteed Conditional Performance of Control Charts via Bootstrap Methods,"To use control charts in practice, the in-control state usually has to be estimated. This estimation has a detrimental effect on the performance of control charts, which is often measured for example by the false alarm probability or the average run length. We suggest an adjustment of the monitoring schemes to overcome these problems. It guarantees, with a certain probability, a conditional performance given the estimated in-control state. The suggested method is based on bootstrapping the data used to estimate the in-control state. The method applies to different types of control charts, and also works with charts based on regression models, survival models, etc. If a nonparametric bootstrap is used, the method is robust to model errors. We show large sample properties of the adjustment. The usefulness of our approach is demonstrated through simulation studies.",Axel Gandy|Jan Terje Kvaløy,,https://arxiv.org/abs/1111.4180v1,https://arxiv.org/pdf/1111.4180v1,https://doi.org/10.1002/sjos.12006,"21 pages, 5 figures",,10.1002/sjos.12006,stat.ME,stat.ME|math.ST,https://arxiv.org/pdf/1111.4180v1.pdf
1111.1826v1,2011-11-08T08:35:03Z,2011-11-08 08:35:03,Monitoring Software Reliability using Statistical Process control: An MMLE approach,This paper consider an MMLE (Modified Maximum Likelihood Estimation) based scheme to estimate software reliability using exponential distribution. The MMLE is one of the generalized frameworks of software reliability models of Non Homogeneous Poisson Processes (NHPPs). The MMLE gives analytical estimators rather than an iterative approximation to estimate the parameters. In this paper we proposed SPC (Statistical Process Control) Charts mechanism to determine the software quality using inter failure times data. The Control charts can be used to measure whether the software process is statistically under control or not.,R. Satya Prasad|Bandla Sreenivasa Rao|R. R. L. Kantam,,https://arxiv.org/abs/1111.1826v1,https://arxiv.org/pdf/1111.1826v1,,"International Journal of Computer Science & Information Technology (IJCSIT) Vol 3, No 5, Oct 2011",,,cs.SE,cs.SE,https://arxiv.org/pdf/1111.1826v1.pdf
1007.3225v1,2010-07-19T18:03:45Z,2010-07-19 18:03:45,New Sensitizing Runs Rules for Shewhart type Control Charts with Applications,The most popular tool used in the industry for monitoring a process is the Shewhart control chart. The major disadvantage of the Shewhart control chart is that it is not very efficient in detecting small process average shifts. To increase the sensitivity of Shewhart control charts to small shifts additional supplementary runs rules has been suggested. In this paper we introduce and study the modified r/m control chart which has an improved sensitivity to small and moderate process average shifts as compared with the standard Shewhart X-bar control chart and corresponding control charts proposed recently in the literature.,Demetrios L. Antzoulakos|Athanasios C. Rakitzis,,https://arxiv.org/abs/1007.3225v1,https://arxiv.org/pdf/1007.3225v1,,"6 pages, 5 Tables, Presented in the 7th Hellenic-European Conference on Computer Mathematics and its Applications",,,stat.AP,stat.AP,https://arxiv.org/pdf/1007.3225v1.pdf
1005.4641v1,2010-05-25T17:36:22Z,2010-05-25 17:36:22,Network-wide Statistical Modeling and Prediction of Computer Traffic,"In order to maintain consistent quality of service, computer network engineers face the task of monitoring the traffic fluctuations on the individual links making up the network. However, due to resource constraints and limited access, it is not possible to directly measure all the links. Starting with a physically interpretable probabilistic model of network-wide traffic, we demonstrate how an expensively obtained set of measurements may be used to develop a network-specific model of the traffic across the network. This model may then be used in conjunction with easily obtainable measurements to provide more accurate prediction than is possible with only the inexpensive measurements. We show that the model, once learned may be used for the same network for many different periods of traffic. Finally, we show an application of the prediction technique to create relevant control charts for detection and isolation of shifts in network traffic.",Joel Vaughan|Stilian A. Stoev|George Michailidis,,https://arxiv.org/abs/1005.4641v1,https://arxiv.org/pdf/1005.4641v1,,,,,stat.AP,stat.AP|math.ST,https://arxiv.org/pdf/1005.4641v1.pdf
1001.1845v1,2010-01-12T10:57:21Z,2010-01-12 10:57:21,Sequentially Updated Residuals and Detection of Stationary Errors in Polynomial Regression Models,"  The question whether a time series behaves as a random walk or as a station- ary process is an important and delicate problem, particularly arising in financial statistics, econometrics, and engineering. This paper studies the problem to detect sequentially that the error terms in a polynomial regression model no longer behave as a random walk but as a stationary process. We provide the asymptotic distribution theory for a monitoring procedure given by a control chart, i.e., a stopping time, which is related to a well known unit root test statistic calculated from sequentially updated residuals. We provide a functional central limit theorem for the corresponding stochastic process which implies a central limit theorem for the control chart. The finite sample properties are investigated by a simulation study.",Ansgar Steland,,https://arxiv.org/abs/1001.1845v1,https://arxiv.org/pdf/1001.1845v1,,,"Sequential Analysis 2008, 27 (3), 304-329",,math.PR,math.PR|math.ST|stat.ME,https://arxiv.org/pdf/1001.1845v1.pdf
1001.1841v1,2010-01-12T10:43:50Z,2010-01-12 10:43:50,A Binary Control Chart to Detect Small Jumps,"  The classic N p chart gives a signal if the number of successes in a sequence of inde- pendent binary variables exceeds a control limit. Motivated by engineering applications in industrial image processing and, to some extent, financial statistics, we study a simple modification of this chart, which uses only the most recent observations. Our aim is to construct a control chart for detecting a shift of an unknown size, allowing for an unknown distribution of the error terms. Simulation studies indicate that the proposed chart is su- perior in terms of out-of-control average run length, when one is interest in the detection of very small shifts. We provide a (functional) central limit theorem under a change-point model with local alternatives which explains that unexpected and interesting behavior. Since real observations are often not independent, the question arises whether these re- sults still hold true for the dependent case. Indeed, our asymptotic results work under the fairly general condition that the observations form a martingale difference array. This enlarges the applicability of our results considerably, firstly, to a large class time series models, and, secondly, to locally dependent image data, as we demonstrate by an example.",Ansgar Steland|Ewaryst Rafalowicz,,https://arxiv.org/abs/1001.1841v1,https://arxiv.org/pdf/1001.1841v1,,,"Statistics 2009, 43 (3), 295-311",,stat.ME,stat.ME|stat.AP|stat.ML,https://arxiv.org/pdf/1001.1841v1.pdf
1001.1833v1,2010-01-12T09:51:16Z,2010-01-12 09:51:16,Weighted Dickey-Fuller Processes for Detecting Stationarity,"  Aiming at monitoring a time series to detect stationarity as soon as possible, we introduce monitoring procedures based on kernel-weighted sequential Dickey-Fuller (DF) processes, and related stopping times, which may be called weighted Dickey-Fuller control charts. Under rather weak assumptions, (functional) central limit theorems are established under the unit root null hypothesis and local-to-unity alternatives. For gen- eral dependent and heterogeneous innovation sequences the limit processes depend on a nuisance parameter. In this case of practical interest, one can use estimated control limits obtained from the estimated asymptotic law. Another easy-to-use approach is to transform the DF processes to obtain limit laws which are invariant with respect to the nuisance pa- rameter. We provide asymptotic theory for both approaches and compare their statistical behavior in finite samples by simulation.",Ansgar Steland,,https://arxiv.org/abs/1001.1833v1,https://arxiv.org/pdf/1001.1833v1,,,"Journal of Statistical Planning and Inference 2007, 137 (12), 4011-4030",,math.PR,math.PR|math.ST|stat.ME,https://arxiv.org/pdf/1001.1833v1.pdf
0906.1421v1,2009-06-08T07:12:03Z,2009-06-08 07:12:03,Distribution-free cumulative sum control charts using bootstrap-based control limits,"  This paper deals with phase II, univariate, statistical process control when a set of in-control data is available, and when both the in-control and out-of-control distributions of the process are unknown. Existing process control techniques typically require substantial knowledge about the in-control and out-of-control distributions of the process, which is often difficult to obtain in practice. We propose (a) using a sequence of control limits for the cumulative sum (CUSUM) control charts, where the control limits are determined by the conditional distribution of the CUSUM statistic given the last time it was zero, and (b) estimating the control limits by bootstrap. Traditionally, the CUSUM control chart uses a single control limit, which is obtained under the assumption that the in-control and out-of-control distributions of the process are Normal. When the normality assumption is not valid, which is often true in applications, the actual in-control average run length, defined to be the expected time duration before the control chart signals a process change, is quite different from the nominal in-control average run length. This limitation is mostly eliminated in the proposed procedure, which is distribution-free and robust against different choices of the in-control and out-of-control distributions.",Snigdhansu Chatterjee|Peihua Qiu,,https://arxiv.org/abs/0906.1421v1,https://arxiv.org/pdf/0906.1421v1,https://doi.org/10.1214/08-AOAS197,Published in at http://dx.doi.org/10.1214/08-AOAS197 the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org),"Annals of Applied Statistics 2009, Vol. 3, No. 1, 349-369",10.1214/08-AOAS197,stat.AP,stat.AP,https://arxiv.org/pdf/0906.1421v1.pdf
0901.2880v1,2009-01-19T15:20:54Z,2009-01-19 15:20:54,Multivariate Statistical Process Control Charts and the Problem of Interpretation: A Short Overview and Some Applications in Industry,"  Woodall and Montgomery [35] in a discussion paper, state that multivariate process control is one of the most rapidly developing sections of statistical process control. Nowadays, in industry, there are many situations in which the simultaneous monitoring or control, of two or more related quality - process characteristics is necessary. Process monitoring problems in which several related variables are of interest are collectively known as Multivariate Statistical Process Control (MSPC).This article has three parts. In the first part, we discuss in brief the basic procedures for the implementation of multivariate statistical process control via control charting. In the second part we present the most useful procedures for interpreting the out-of-control variable when a control charting procedure gives an out-of-control signal in a multivariate process. Finally, in the third part, we present applications of multivariate statistical process control in the area of industrial process control, informatics, and business.",S. Bersimis|J. Panaretos|S. Psarakis,,https://arxiv.org/abs/0901.2880v1,https://arxiv.org/pdf/0901.2880v1,,,"Proceedings of the 7th Hellenic European Conference on Computer Mathematics and its Applications, Athens, Greece, 2005",,stat.AP,stat.AP,https://arxiv.org/pdf/0901.2880v1.pdf
0805.2292v1,2008-05-15T12:59:12Z,2008-05-15 12:59:12,A nonparametric control chart based on the Mann-Whitney statistic,"  Nonparametric or distribution-free charts can be useful in statistical process control problems when there is limited or lack of knowledge about the underlying process distribution. In this paper, a phase II Shewhart-type chart is considered for location, based on reference data from phase I analysis and the well-known Mann-Whitney statistic. Control limits are computed using Lugannani-Rice-saddlepoint, Edgeworth, and other approximations along with Monte Carlo estimation. The derivations take account of estimation and the dependence from the use of a reference sample. An illustrative numerical example is presented. The in-control performance of the proposed chart is shown to be much superior to the classical Shewhart $\bar{X}$ chart. Further comparisons on the basis of some percentiles of the out-of-control conditional run length distribution and the unconditional out-of-control ARL show that the proposed chart is almost as good as the Shewhart $\bar{X}$ chart for the normal distribution, but is more powerful for a heavy-tailed distribution such as the Laplace, or for a skewed distribution such as the Gamma. Interactive software, enabling a complete implementation of the chart, is made available on a website.",Subhabrata Chakraborti|Mark A. van de Wiel,,https://arxiv.org/abs/0805.2292v1,https://arxiv.org/pdf/0805.2292v1,https://doi.org/10.1214/193940307000000112,Published in at http://dx.doi.org/10.1214/193940307000000112 the IMS Collections (http://www.imstat.org/publications/imscollections.htm) by the Institute of Mathematical Statistics (http://www.imstat.org),"IMS Collections 2008, Vol. 1, 156-172",10.1214/193940307000000112,stat.ME,stat.ME,https://arxiv.org/pdf/0805.2292v1.pdf
0804.4325v1,2008-04-28T06:10:00Z,2008-04-28 06:10:00,Intégration du contrôle automatique dans la maîtrise statistique des procédés,"  The Statistical Process Control (SPC) and the Automated Process Control (APC) have a common goal: achieve optimal product quality by controlling variations in the process. The work in this paper will present a developed integration methodology of the APC in the SPC which is based on discretization of the transfer functions relating to each component of the process. We proposed on the one hand, a new control rule which is based on a system of first order. In the other hand, we showed how to establish control charts to a process of the type AR (1). Using simulation experiments, we showed that the proposed control rule reduced variability by comparing it with that proposed in literature.",Wafik Hachicha|Ahmed Ammeri|Sami Abidi|Faouzi Masmoudi,U2MP|U2MP|U2MP|U2MP,https://arxiv.org/abs/0804.4325v1,https://arxiv.org/pdf/0804.4325v1,,,"In:Conférence internationale sur le thème : Maîtrise et Management des Risques Industriels (M2RI'2008), Oujda : Maroc (2008)",,stat.AP,stat.AP,https://arxiv.org/pdf/0804.4325v1.pdf
0802.0218v1,2008-02-01T22:46:05Z,2008-02-01 22:46:05,Multivariate control charts based on Bayesian state space models,"  This paper develops a new multivariate control charting method for vector autocorrelated and serially correlated processes. The main idea is to propose a Bayesian multivariate local level model, which is a generalization of the Shewhart-Deming model for autocorrelated processes, in order to provide the predictive error distribution of the process and then to apply a univariate modified EWMA control chart to the logarithm of the Bayes' factors of the predictive error density versus the target error density. The resulting chart is proposed as capable to deal with both the non-normality and the autocorrelation structure of the log Bayes' factors. The new control charting scheme is general in application and it has the advantage to control simultaneously not only the process mean vector and the dispersion covariance matrix, but also the entire target distribution of the process. Two examples of London metal exchange data and of production time series data illustrate the capabilities of the new control chart.",K. Triantafyllopoulos,,https://arxiv.org/abs/0802.0218v1,https://arxiv.org/pdf/0802.0218v1,https://doi.org/10.1002/qre.807,"19 pages, 6 figures","Quality and Reliability Engineering International (2006), 22(6), pp. 693-707",10.1002/qre.807,stat.ME,stat.ME|stat.AP,https://arxiv.org/pdf/0802.0218v1.pdf
