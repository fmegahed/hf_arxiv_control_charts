{
  "metadata": {
    "generated_at": "2026-02-02T12:15:58Z",
    "week_start": "2026-01-26",
    "week_end": "2026-02-02",
    "version": "3.1.0"
  },
  "summary": {
    "total_papers": 3,
    "papers_by_track": {
      "spc": 0,
      "exp_design": 1,
      "reliability": 2
    }
  },
  "synthesis": "## QE ArXiv Watch Weekly — Week ending Feb 02, 2026 (3 papers)\n\nIf you’ve ever trusted a “loss went down” plot and still ended up with a model that behaves oddly in production, you’ll appreciate this week’s best wake-up call: **cross-entropy can go to zero while the *gradient you actually use for guidance* stays wrong—or even blows up.** That’s not a philosophical nit. It’s a concrete failure mode with proofs and toy experiments you can recreate.\n\n### When “good classifier” doesn’t mean “good guidance” (Sahu et al.)\nClassifier-guided diffusion hinges on a vector field: the gradient of the log-conditional, \\(\\nabla \\log p(y\\mid x_t)\\). Most training focuses on cross-entropy (conditional KL). The catch: **a small KL gap doesn’t necessarily control gradient error.**\n\nThey build explicit high-frequency perturbations where the classifier’s KL error vanishes (think \\(O(1/n)\\)), yet the guidance-gradient error stays \\(\\Omega(1)\\), and in a stronger construction the gradient error grows like \\(\\Omega(n)\\) while KL still shrinks. In other words, the classifier can be “right on average” but **locally jagged**, and guidance cares about local geometry.\n\nThe constructive part is the remedy: if you assume bounded support and real smoothness/regularity—bounds on gradients and Hessians aligned with the true conditional—then cross-entropy error \\(\\varepsilon\\) *does* imply an \\(L_2\\) guidance-gradient MSE bound scaling roughly like  \n\\[\n\\tilde O\\Big(\\frac{d(\\varepsilon+\\varepsilon^2)}{\\sigma_t^2\\,P(y)^{3/2}}\\Big),\n\\]\nwhich also clarifies where guidance gets fragile: **high dimension \\(d\\), low noise \\(\\sigma_t\\), and rare classes \\(P(y)\\).** They push through to sampler error bounds and a step complexity result that stays near-linear in dimension, which is reassuring if you’re budgeting compute.\n\n**Practitioner takeaway:** if you’re deploying guided generative models for inspection images or defect synthesis, don’t stop at “validation CE looks fine.” Add **gradient-focused diagnostics** (stability/Lipschitz proxies, smoothing/regularization, stress tests at low \\(\\sigma_t\\), and especially checks for rare-class guidance).\n\n---\n\n### Self-supervised ultrasound enhancement that acts like a reliability preprocessor (Khan et al.)\nUltrasound is a worst-case “measurement system”: speckle-like noise, PSF blur, and often no clean reference. The clever move here is **self-supervised training pairs from real frames** using a physics-guided degradation model—Gaussian PSF surrogate blur plus noise (either additive Gaussian or Fourier-domain complex perturbations)—and “clean-like” targets created via **non-local low-rank denoising**.\n\nThe restoration net is a Swin-Convolutional U-Net (local conv + shifted-window attention), and the reported gains are not just cosmetic: across datasets and blur levels they claim **+3.6 to +13.8 dB PSNR** and **+0.01 to +0.26 SSIM**, plus sharper edges (FWHM down, gradient metrics up). The most QE-relevant result: as a plug-in preprocessor it **improves downstream segmentation Dice** under severe noise—exactly where pipelines usually fall apart.\n\n**Where you might try it:** any imaging-driven decision where you can’t recalibrate the sensor (fielded systems, legacy probes, multi-site variability). Treat it like a **front-end robustness module** and measure impact on your actual CTQ (segmentation, detection, measurement repeatability), not just PSNR.\n\n---\n\n### DOE meets matching: randomize locally, not globally (Wang et al.)\nIf you’ve ever evaluated two matching policies (assignments, pairing, workforce-to-task) and felt that “just randomize which matching we use” is too blunt—you’re right. Switching wholesale between two matchings can have **non-vanishing variance** because match feasibility creates interference.\n\nThey exploit a beautiful graph fact: the *disagreement edges* between two one-to-one matchings decompose into disjoint alternating paths and even cycles. That decomposition localizes interference. Their **Alternating Path (AP) Design** randomizes within each component with a single parameter \\(p\\), keeping feasibility intact, and pairs with a Horvitz–Thompson estimator.\n\nUnder worst-case bounded outcomes, variance drops like **\\(O(1/N)\\)** (versus constant variance for the naive switch). Even better, the minimax-optimal \\(p\\) for long components converges to \\(\\sqrt2-1 \\approx 0.4142\\)—a rare “use this number on Monday” result. Simulations show AP variance shrinking with size while naive variance stays ~flat, and a finite-population CLT supports normal approximations for inference.\n\n**QE angle:** this is design-based causal inference for operational systems with constraints—exactly the kind of scenario we see in allocation, routing, pairing, and staffing.\n\n---\n\n### The connective tissue this week\nAcross all three: **we’re getting more honest about what our objectives actually control.** Cross-entropy doesn’t guarantee good guidance; PSNR doesn’t guarantee better segmentation; global randomization doesn’t guarantee good precision under interference. The win comes from targeting the quantity that drives the decision.\n\n**Question to ponder:** in your current pipeline, what’s the equivalent of “training the wrong loss”—the metric that looks reassuring but doesn’t control the failure mode you care about?",
  "papers": [
    {
      "id": "2601.21856v1",
      "title": "Blind Ultrasound Image Enhancement via Self-Supervised Physics-Guided Degradation Modeling",
      "authors": "Shujaat Khan|Syed Muhammad Atif|Jaeyoung Huh|Syed Saad Azhar",
      "submitted": "2026-01-29",
      "track": "reliability",
      "link": "https://arxiv.org/pdf/2601.21856v1"
    },
    {
      "id": "2601.21200v1",
      "title": "Provably Reliable Classifier Guidance through Cross-entropy Error Control",
      "authors": "Sharan Sahu|Arisina Banerjee|Yuchen Wu",
      "submitted": "2026-01-29",
      "track": "reliability",
      "link": "https://arxiv.org/pdf/2601.21200v1"
    },
    {
      "id": "2601.21036v1",
      "title": "Experimental Design for Matching",
      "authors": "Chonghuan Wang",
      "submitted": "2026-01-28",
      "track": "exp_design",
      "link": "https://arxiv.org/pdf/2601.21036v1"
    }
  ]
}
